{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harrison Jansma\n",
    "\n",
    "<img src='https://harrisonjansma.com/img/harrison.png' width=100>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__3.__\n",
    "Part 1: What is the arithmetic intensity for matrix matrix multiplication\n",
    "with sizes M, N and K (BLAS notation)? Part 2: Prove that arithmetic intensity for matrix matrix\n",
    "multiplication is maximized when M = N = K (all matrices are square).\n",
    "\n",
    "__Solution:__ While multiplying two matrices we have the following operations:\n",
    "\n",
    "- N multiplications across K rows M times -> MNK MACs\n",
    "- 2 Loads MK, KN and one store MN -> MK+KN+MN Mem Ops\n",
    "\n",
    "<center>$Arithmetic Intensity = \\frac{MNK}{(MK+KN+MN)}$</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "__4.__\n",
    "Consider a dense layer that transforms input feature vectors to output feature vectors of the\n",
    "same length (No = Ni). Ignoring the bias and pointwise nonlinearity, what is the complexity\n",
    "(MACs and memory) of this layer applied to inputs created from vectorized versions of the\n",
    "following:\n",
    "\n",
    "- MNIST: 1 x 28 x 28\n",
    "- CIFAR: 3 x 32 x 32\n",
    "- ImageNet: 3 x 224 x 224 (typical use)\n",
    "- Quasi 1/4 HD: 3 x 512 x 1024\n",
    "- Quasi HD: 3 x 1024 x 2048\n",
    "\n",
    "__Solution:__\n",
    "Complexity is $\\frac{K^{2}}{2K+K^{2}}$ Because $K=N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T02:55:27.022099Z",
     "start_time": "2020-01-30T02:55:27.014122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  (MACs, Memory)\n",
      "MNIST:  (614656, 616224)\n",
      "CIFAR:  (9437184, 9443328)\n",
      "ImageNet:  (22658678784, 22658979840)\n",
      "Quasi 1/ HD:  (2473901162496, 2473904308224)\n",
      "Quasi HD:  (39582418599936, 39582431182848)\n"
     ]
    }
   ],
   "source": [
    "def solve_question_four(C,H,W):\n",
    "    K = C*H*W\n",
    "    return K**2 , (2*K + K**2)\n",
    "\n",
    "print(\"Dataset:  (MACs, Memory)\")\n",
    "print(\"MNIST: \", solve_question_four(1,28,28),)\n",
    "print(\"CIFAR: \", solve_question_four(3,32,32))\n",
    "print(\"ImageNet: \", solve_question_four(3,224,224))\n",
    "print(\"Quasi 1/ HD: \", solve_question_four(3,512,1024))\n",
    "print(\"Quasi HD: \", solve_question_four(3,1024,2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5.__ \n",
    "In practice, why can’t you flatten a quasi HD input image (3 x 1024 x 2048) to a 6291456 x 1\n",
    "vector and use densely connected layers to transform from data to weak features to strong features to classes?\n",
    "\n",
    "__Solution:__\n",
    "Way to many Parameters. This would hinder training due to the number of operations that need to be performed as well as the sheer memory requirements of having to store not only the parameters, but every intermediate product and gradient.\n",
    "\n",
    "__6.__\n",
    "Say I have trained a dense layer for an input of size 1024 x 1. Can this dense layer be applied\n",
    "to an input of size 2048 x 1? What about 512 x 1?\n",
    "\n",
    "__Solution:__ Fixed size input, the input image resolution would have to be the same as the training data.\n",
    "\n",
    "__8.__\n",
    "Consider a CNN style 2D convolution layer with filter size No x Ni x Fr x Fc. How many MACs\n",
    "are required to compute each output point?\n",
    "\n",
    "__Solution:__ So based on the wording of this question, I am assuming that the operation will be one step in the convolution of a single filter.\n",
    "\n",
    "MACs: $F_r*F_c*N_i$\n",
    "\n",
    "\n",
    "\n",
    "__9.__\n",
    "How does CNN style 2D convolution complexity (MACs and memory) scale as a function of\n",
    "- Product of the image rows and cols (Lr*Lc)?\n",
    "- Product of the filter rows and cols (Fr*Fc), assume Ni and No are fixed?\n",
    "- Product of the number of input and output feature maps (Ni*No)?\n",
    "\n",
    "__Solution:__\n",
    "\n",
    "\n",
    "\n",
    "__10.__\n",
    "Consider a CNN style 2D convolution layer with filter size No x Ni x Fr x Fc. How many 0s do I\n",
    "need to pad the input feature map with such that the output feature map is the same size as the\n",
    "input feature map (before 0 padding)? What is the size of the border of 0s for Fr = Fc = 1? What\n",
    "is the size of the border of 0s for Fr = Fc = 3? What is the size of the border of 0s for Fr = Fc = 5?\n",
    "\n",
    "__SOlution:__\n",
    "Row Pad: $F_r-1$ Col Pad: $F_c-1$\n",
    "\n",
    "No border required\n",
    "\n",
    "1 pixels thick on both rows and columns.\n",
    "\n",
    "2 pixels thick on rows and columns\n",
    "\n",
    "\n",
    "__11.__\n",
    "Consider a CNN style 2D convolution layer with No x Ni x Fr x Fc filter, Ni x Lr x Lc input (Lr and\n",
    "Lc both even) and Pr = Fr – 1 and Pc = Fc – 1 zero padding. What is the size of the output feature\n",
    "map with striding Sr = Sc = 1 (no striding)? What is the size of the output feature map with\n",
    "striding Sr = Sc = 2? How does this change the shape of the equivalent lowered matrix equation?\n",
    "\n",
    "__SOlution:__\n",
    "\n",
    "No Striding: $N_o*L_r*L_c $\n",
    "\n",
    "Striding=2: $N_o*\\frac{L_r*L_c}{2}$\n",
    "\n",
    "The filter tensor doesn't change. For the input map something like: Keep the first of every three groups of columns of length W. Within the kept group of tensors, keep the first column of every three.\n",
    "\n",
    "\n",
    "\n",
    "__12.__\n",
    "Say I have trained a CNN style 2D convolution layer for an input of size 3 x 1024 x 2048. Can\n",
    "this CNN style 2D convolution layer be applied to an input of size 3 x 512 x 1024? What about 3\n",
    "x 512 x 512?\n",
    "\n",
    "__Solution:__\n",
    "Yes, the convolutional layer is compatable with different sized inputs (except the channel dimension).\n",
    "\n",
    "\n",
    "__RNN layers__\n",
    "\n",
    "\n",
    "__13.__\n",
    "In a standard RNN, if the state update matrix is constrained to a diagonal, what does this do\n",
    "for the mixing of the previous state with new inputs?\n",
    "\n",
    "\n",
    "__Solution:__\n",
    "This would be one big linear layer, since there is no mixing of information across time.\n",
    "\n",
    "__Attention layers__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__14.__\n",
    "Consider single headed self attention where input XT is a M x K matrix composed of M input\n",
    "vectors with K features per vector, Ai\n",
    "T is a M x M attention matrix where each element is non\n",
    "negative and each row sums to 1 (think each row is a pmf), Wv,i is a K x L weight matrix and\n",
    "output Yi\n",
    "T is a M x L matrix composed of M output vectors with L features per vector\n",
    "Yi\n",
    "T = Ai\n",
    "T XT Wv,i\n",
    "Can Ai\n",
    "T be computed once and then used for all inputs? What does it mean for the output if Ai\n",
    "T\n",
    "is an identity matrix? What does it mean for the output if Wv,i is an identity matrix?\n",
    "\n",
    "__Solution__\n",
    "No the formula for A depends on X.\n",
    "\n",
    "Then the output of the Attention* input multiplication is identical to the input matrix -> Linear layer without a bias\n",
    "\n",
    "We will have mixing across inputs but no mixing. Not really sure how this would work.\n",
    "\n",
    "\n",
    "#### Average pooling layers\n",
    "__15.__\n",
    "The size of the input to a global average pooling layer is 1024 x 16 x 32. What is the size of\n",
    "the output? What is the complexity (operations) of the layer?\n",
    "\n",
    "__Solution:__\n",
    "\n",
    "1024x1\n",
    "\n",
    "$16*32$ operations for each of the 1024 channels.\n",
    "\n",
    "\n",
    "[I've executed the MNIST Code on AWS](https://github.com/harrisonjansma/2019_Notes/blob/master/DL/Frameworks/TensorFlow/1_Model_Customization.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning]",
   "language": "python",
   "name": "conda-env-deep-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
