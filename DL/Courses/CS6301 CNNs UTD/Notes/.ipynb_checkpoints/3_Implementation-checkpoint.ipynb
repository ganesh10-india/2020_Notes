{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[slides](https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/blob/master/Lectures/xNNs_070_Implementation.pdf)\n",
    "\n",
    "[disk](file:///F:/Data/xNNs_070_Implementation.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Notes\n",
    "\n",
    "## Hardware and Software\n",
    "\n",
    "Software can be more general (hardware agnostic) that leans on runtime intelligent hardware to optimize the perforance of the program duting execution. \n",
    "\n",
    "Software can rely on compile time intelligent hardware. \n",
    "\n",
    "__Graph Specification__ Is a representation of a high-level hardware agnostic computer algorithm. nodes are operators. Implicit data and instruction movement. Edges prepresent dependenies (memory)\n",
    "\n",
    "__Graph Lowering__ Map a high level program to a low-level, hardware specific graph. Includes compute and communication nodes, as well as data and instruction edges. Nodes map 1 to 1 to hardware.\n",
    "\n",
    "This is an iterative optimization process that can be improved with knowledge of domain and hardware.\n",
    "\n",
    "__Graph Execution__ Sofftware runtime runs on a control processor and cycles through nodes on the low level graph. Hardware execures the nodes with computation and communication primitives as well as general compute for everything else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized XNN Design\n",
    "\n",
    "Some hardware aware design considerations:\n",
    "- Operator selection: quantization, sparisification, and compression\n",
    "- Network sizing: depth, width, input size\n",
    "\n",
    "__Quantization__ reduces the number of bits required to represent feature maps and parameters. \n",
    "\n",
    "Quantizing deep convolutional networks for efficient inference: A whitepaper\n",
    "https://arxiv.org/abs/1806.08342\n",
    "\n",
    "*Per-channel quantization of weights and per-layer quantization of activations to 8-bits of precision post-training produces classification accuracies within 2% of floating point networks for a wide variety of CNN architectures. Model sizes can be reduced by a factor of 4 by quantizing weights to 8-bits, even when 8-bit arithmetic is not supported...Observe a speedup of 2x-3x for quantized implementations compared to floating point on CPUs*\n",
    "\n",
    "*We recommend that per-channel quantization of weights and per-layer quantization of activations be the preferred quantization scheme for hardware acceleration and kernel optimization. We also propose that future processors and hardware accelerators for optimized inference support precisions of 4, 8 and 16 bits.*\n",
    "\n",
    "Reduces memory and communication requirements of the network. Multiplication complexity scales to the square of the number of bits, while addition scales linearly with the number of bits.\n",
    "\n",
    "32 bit float, 16 bit float, 8 bit fixed (common for CNN inference), and 4 bit fixed\n",
    "\n",
    "__Sparsification__\n",
    "\n",
    "Reduces memory and the required number of computations. Random sparsity can be introduced with L1 regularization as well as thresholding dense coefficient values.\n",
    "\n",
    "Network pruning methods exist. Using second oreder derivatives of parameters wrt error function\n",
    "\n",
    "https://openreview.net/pdf?id=Sy1iIDkPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XNN Software\n",
    "\n",
    "__CNN Graph Lowering__\n",
    "\n",
    "• Domain agnostic hardware agnostic optimization\n",
    "    - Remove unneeded edges and nodes required for specified input output\n",
    "    - Constant folding and constant propagation\n",
    "    \n",
    "• Domain specific hardware agnostic optimization\n",
    "    - xNNs: remove dropout and scale associated weight layers\n",
    "    - xNNs: absorb batch norm into convolution and create a bias term\n",
    "\n",
    "• Domain specific hardware aware optimization\n",
    "    - xNNs: transform data layouts (tensor ordering)\n",
    "    - xNNs: node fusion, tiling and grouping\n",
    "    - xNNs: post training quantization\n",
    "\n",
    "• Domain agnostic hardware specific code generation\n",
    "    - Memory planning for all tensors\n",
    "    - Data movement and compute strategy selection for each node\n",
    "    - Code generation for selected strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XNN Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning]",
   "language": "python",
   "name": "conda-env-deep-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
