{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T17:02:40.064980Z",
     "start_time": "2020-01-24T17:02:35.563375Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0 Notes\n",
    "\n",
    "Link to [TensorFlow Guide](https://www.tensorflow.org/guide/effective_tf2).\n",
    "\n",
    "### Effective TensorFlow 2\n",
    "\n",
    "- Look for useful tools in `tf.keras.metrics` and `tf.keras.optimizers`.\n",
    "- Keep track of your variables! If you lose track of a `tf.Variable`, it gets garbage collected.\n",
    "- In TensorFlow 2.0, you can decorate a Python function using `tf.function()` to mark it for JIT compilation so that TensorFlow runs it as a single graph\n",
    "- To help users avoid having to rewrite their code when adding `@tf.function`, AutoGraph converts a subset of Python constructs into their TensorFlow equivalents:\n",
    "\n",
    "#### Recommendations for Idiomatic TensorFlow 2.0\n",
    "\n",
    "- Refactor your code into smaller functions __it's not necessary to decorate each of these smaller functions with `tf.function`__; only use tf.function to decorate high-level computations - for example, one step of training or the forward pass of your model.\n",
    "- Use Keras layers and models to manage variables (pretty much identical to the PyTorch API\n",
    "- Combine `tf.data.Datasets` and `@tf.function`. Dataset is the best way to stream memory from disk, wrapping code in @tf.function takes advantage of dataset asynchonous loading\n",
    "\n",
    "- `tf.metrics` aggregates data and `tf.summary` logs them.Metrics are stateful: They accumulate values and return a cumulative result when you call .result(). Clear accumulated values with `.reset_states()`.\n",
    "\n",
    "- se `tf.config.experimental_run_functions_eagerly()` when debugging\n",
    "\n",
    "\n",
    "### Better performance with tf.function and AutoGraph\n",
    " At the center of this merger is `tf.function`, which allows you to transform a subset of Python syntax into portable, high-performance TensorFlow graphs.\n",
    " \n",
    " When you annotate a function with tf.function, you can still call it like any other function. But it will be compiled into a graph, which means you get the benefits of faster execution, running on GPU or TPU, or exporting to SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def square_if_positive(x):\n",
    "    if x > 0:\n",
    "        x = x * x\n",
    "    else:\n",
    "        x = 0\n",
    "    return x\n",
    "\n",
    "\n",
    "print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\n",
    "print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGraph supports common Python statements like while, for, if, break, continue and return, with support for nesting.\n",
    "\n",
    "n real applications batching is essential for performance. __The best code to convert to AutoGraph is code where the control flow is decided at the batch level.__ If making decisions at the individual example level, try to use batch APIs to maintain performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_if_positive_vectorized(x):\n",
    "    return tf.where(x > 0, x ** 2, x)\n",
    "\n",
    "square_if_positive_vectorized(tf.range(-5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.function can give you significant speedup over eager execution, at the cost of a slower first-time execution. This is because when executed for the first time, the function is also traced into a TensorFlow graph.bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras\n",
    "\n",
    "\n",
    "In Keras, you assemble layers to build models. A model is (usually) a graph of layers. The most common type of model is a stack of layers: the `tf.keras.Sequential` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is constructed, configure its learning process by calling the `compile` method:\n",
    "\n",
    "- Loss functions are specified by name or by passing a callable object from the tf.keras.losses module.\n",
    "- metrics: Used to monitor training. These are string names or callables from the tf.keras.metrics module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Datasets API to scale to large datasets or multi-device training. Pass a `tf.data.Dataset` instance to the fit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A callback is an object passed to a model to customize and extend its behavior during training. You can write your own custom callback, or use the built-in tf.keras.callbacks that include:\n",
    "\n",
    "- `tf.keras.callbacks.ModelCheckpoint`: Save checkpoints of your model at regular intervals.\n",
    "- `tf.keras.callbacks.LearningRateScheduler`: Dynamically change the learning rate.\n",
    "- `tf.keras.callbacks.EarlyStopping`: Interrupt training when validation performance has stopped improving.\n",
    "- `tf.keras.callbacks.TensorBoard`: Monitor the model's behavior using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights to a TensorFlow Checkpoint file\n",
    "model.save_weights('./weights/my_model')\n",
    "\n",
    "# Restore the model's state,\n",
    "# this requires a model with the same architecture.\n",
    "model.load_weights('./weights/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Keras Functional API__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name='img')\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/save_and_serialize\n",
    "\n",
    "https://www.tensorflow.org/guide/estimator\n",
    "\n",
    "https://www.tensorflow.org/guide/eager\n",
    "\n",
    "https://www.tensorflow.org/guide/variable\n",
    "\n",
    "https://www.tensorflow.org/guide/tensor\n",
    "\n",
    "https://www.tensorflow.org/guide/data\n",
    "\n",
    "https://www.tensorflow.org/guide/checkpoint\n",
    "\n",
    "https://www.tensorflow.org/guide/distributed_training\n",
    "\n",
    "https://www.tensorflow.org/guide/gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning]",
   "language": "python",
   "name": "conda-env-deep-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
