{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition\n",
    "\n",
    "Making a thing for someone. \n",
    "## Idea\n",
    "So all of the facial recognition models I could find on GitHub were super old (2017) The best ones I could find were, [facenet](https://github.com/davidsandberg/facenet) and another repo based on dllib [facial_recognition](https://github.com/ageitgey/face_recognition). Well these are great, but I really want a implementation in TF2. That way i can deploy it to a web app with [cortex](https://github.com/cortexlabs/cortex) and integrate it into an idea for this web application I want to make.\n",
    "\n",
    "## Steps\n",
    "1. Download training data to learn via crossentropy loss unlike in [FaceNet Paper](https://arxiv.org/abs/1503.03832) This way I can generize to different data by chopping off the head.\n",
    "2. Include examples that are meant to trick the model. (Someone holding a phone with a picture of a face up) Make a seperate training category. Pictures of pics, masks,...\n",
    "3. Load the Resnet_V2 architecture from TFhub and setup the code for softmax. Compare with MobileNet and other architectures\n",
    "4. Train the models\n",
    "5. Save the model parameters\n",
    "6. Make a script to chop off head and retrain based on a certain directory (still keep adversarial example class)\n",
    "\n",
    "\n",
    "## Notes\n",
    "- I will be loading the pretrained [resnet_v2](https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4), so hopefully the model will converge faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Resources\n",
    "- [VGG Dataset](http://zeus.robots.ox.ac.uk/vgg_face2/)\n",
    "- [VGG Model Repo](https://github.com/WeidiXie/Keras-VGGFace2-ResNet50)\n",
    "- [FaceNet Repo](https://github.com/davidsandberg/facenet)\n",
    "- [ResNet V2 TFHub](https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning]",
   "language": "python",
   "name": "conda-env-deep-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
