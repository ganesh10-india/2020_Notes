{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations\n",
    "https://jhui.github.io/2018/02/09/PyTorch-Basic-operations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(2,3)\n",
    "print(x) #float tensor of zeros size=(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "#OPERATION SYNTAX\n",
    "y = torch.rand(2,3)\n",
    "z1 = x + y  #operator overloading\n",
    "z2 = torch.add(x,y) #same as above\n",
    "print(z1==z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.9271e-01, 7.0030e-01, 3.4164e+21],\n",
      "        [2.7881e-01, 4.7309e-01, 1.4451e-01]])\n"
     ]
    }
   ],
   "source": [
    "#INPLACE OPERATIONS\n",
    "#followed by \"_\"\n",
    "x.add_(y)  #add y to x in-place\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0.])\n",
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 0]) #all rows, first column \n",
    "print(x[0, :]) #all columns, first row\n",
    "\n",
    "#the first position in a slice is the outtermost dimension in\n",
    "# vector format (dim1, dim2, dim3) [dim1[dim2[dim3]],[dim2[dim3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#METADATA\n",
    "print(x.size()) #size of x\n",
    "print(torch.numel(x)) #num elements in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1091, -0.7261, -0.0272],\n",
      "        [ 0.1972, -1.8981, -1.3471]])\n",
      "tensor([ 0.1091, -0.7261, -0.0272,  0.1972, -1.8981, -1.3471])\n",
      "tensor([[ 0.1091, -0.7261],\n",
      "        [-0.0272,  0.1972],\n",
      "        [-1.8981, -1.3471]])\n"
     ]
    }
   ],
   "source": [
    "#RESHAPING A TENSOR ~ .VIEW()\n",
    "x = torch.randn(2,3)\n",
    "y = x.view(6)\n",
    "z = x.view(3,-1)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Matrix Fill Tensor w/ 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[[[1.],\n",
      "          [1.]]],\n",
      "\n",
      "\n",
      "        [[[1.],\n",
      "          [1.]]]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "#IDENTITY MATRIX ~ torch.eye()\n",
    "identity = torch.eye(3) #3x3 identity\n",
    "print(identity)\n",
    "\n",
    "#Vector of ones ~ torch.ones()\n",
    "v = torch.ones(2,1,2,1)\n",
    "print(v)\n",
    "v = torch.ones_like(identity) #ones w same shape as identity\n",
    "print(v)\n",
    "\n",
    "#FILL ~ .fill_()\n",
    "v[1].fill_(2) #FILL Second row with 2's\n",
    "v[2].fill_(3)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tensors with Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([0, 2, 4])\n",
      "tensor([ 0.0000,  0.9091,  1.8182,  2.7273,  3.6364,  4.5455,  5.4545,  6.3636,\n",
      "         7.2727,  8.1818,  9.0909, 10.0000])\n",
      "tensor([1.0000e+00, 8.1113e+00, 6.5793e+01, 5.3367e+02, 4.3288e+03, 3.5112e+04,\n",
      "        2.8480e+05, 2.3101e+06, 1.8738e+07, 1.5199e+08, 1.2328e+09, 1.0000e+10])\n"
     ]
    }
   ],
   "source": [
    "# torch.ARANGE()  Returns type long\n",
    "v = torch.arange(0,5)\n",
    "print(v)\n",
    "v = torch.arange(0,5,2) #range(0,5,step=2)\n",
    "print(v)\n",
    "\n",
    "# torch.LINSPACE()   #returns type float\n",
    "v = torch.linspace(0,10,12) #Split [0,10] in 12 linear steps\n",
    "print(v)\n",
    "v = torch.logspace(0,10,12) #split [0,10] in 12 log steps\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, Slicing, Joining, Mutating\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recombining Data\n",
    "- CONCAT join data on an existing dim\n",
    "- STACK join data on a new dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) torch.Size([9, 3]) \n",
      "\n",
      "tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5, 3, 4, 5],\n",
      "        [6, 7, 8, 6, 7, 8, 6, 7, 8]]) torch.Size([3, 9]) \n",
      "\n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]]) torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "v = torch.arange(0,9).view(3, 3)\n",
    "print(v, '\\n')\n",
    "\n",
    "#CONCATENATE, STACK\n",
    "\"\"\"\n",
    "Both cat and stack require tensors of the same shape.\n",
    "CAT - combines on a given EXISTING dimension\n",
    "STACK - combines tensors on a new dimension\n",
    "\"\"\"\n",
    "#torch.CAT()\n",
    "cat = torch.cat((v,v,v), dim=0)\n",
    "print(cat, cat.shape,'\\n')\n",
    "cat = torch.cat((v,v,v), dim=1)\n",
    "print(cat, cat.shape, '\\n')\n",
    "\n",
    "#torch.STACK()\n",
    "stack = torch.stack((v, v))\n",
    "print(stack, stack.shape)#stacks array on a new dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [5, 4, 3],\n",
      "        [8, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "#GATHER: Reorganize Data Elements\n",
    "print(v,'\\n')\n",
    "out = torch.gather(v, 1, torch.LongTensor([[0,1,2],[2,1,0],[2,1,2]]))\n",
    "print(out)\n",
    "# torch.gather(input, dim, index, out=None)\n",
    "# out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\n",
    "# out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\n",
    "# out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate a Tensor into multiple.\n",
    "- CHUNK a tensor into N distinct Tensors\n",
    "- SPLIT a tensor every N rows/columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]), tensor([[6, 7, 8]])) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "(tensor([[0, 1],\n",
      "        [3, 4],\n",
      "        [6, 7]]), tensor([[2],\n",
      "        [5],\n",
      "        [8]])) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "#CHUNK A TENSOR, -> Choost the NUMBER OF OUTPUT TENSORS\n",
    "\"\"\"chunk(input, chunks, dim=0)\n",
    "Splits a tensor into a specific number of chunks.\n",
    "Last chunk will be smaller if the tensor size along the given \n",
    "dimension`dim` is not divisible by `chunks`.\"\"\"\n",
    "\n",
    "#Split the tensor into N chunks on dimension 'dim'\n",
    "\n",
    "#Chunk by rows (2D) ~torch.CHUNK()\n",
    "r = torch.chunk(v, 2, dim=0) #2 Chunks, shape (2,3), (1,3)\n",
    "print(r, '\\n')\n",
    "\n",
    "#Recombine\n",
    "print( torch.cat((r[0],r[1]), dim = 0) ,'\\n')\n",
    "\n",
    "#Chunk by columns (2D)\n",
    "r = torch.chunk(v, 2, 1) # 2 tensors, shape (3,2), (3,1)\n",
    "print(r, '\\n')\n",
    "\n",
    "#Recombine\n",
    "print( torch.cat((r[0],r[1]), dim = 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]]) \n",
      "\n",
      "(tensor([[0, 1, 2, 3, 4]]), tensor([[5, 6, 7, 8, 9]]), tensor([[10, 11, 12, 13, 14]]), tensor([[15, 16, 17, 18, 19]]), tensor([[20, 21, 22, 23, 24]])) \n",
      "\n",
      "(tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]]), tensor([[10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19]]), tensor([[20, 21, 22, 23, 24]])) \n",
      "\n",
      "(tensor([[ 0,  1],\n",
      "        [ 5,  6],\n",
      "        [10, 11],\n",
      "        [15, 16],\n",
      "        [20, 21]]), tensor([[ 2,  3],\n",
      "        [ 7,  8],\n",
      "        [12, 13],\n",
      "        [17, 18],\n",
      "        [22, 23]]), tensor([[ 4],\n",
      "        [ 9],\n",
      "        [14],\n",
      "        [19],\n",
      "        [24]]))\n"
     ]
    }
   ],
   "source": [
    "# SPLIT A TENSOR -> choose the SIZE OF OUTPUT TENSORS\n",
    "\"\"\"\n",
    "torch.split(tensor, split_size_or_sections, dim=0)\n",
    "\"\"\"\n",
    "#Split the tensor every N rows/columns on dimension 'dim'\n",
    "v = torch.arange(0,25).view(5,5)\n",
    "print(v,'\\n')\n",
    "\n",
    "\n",
    "#split every 1 rows \n",
    "r = torch.split(v, 1, 0)\n",
    "print(r,'\\n')\n",
    "\n",
    "#Split every 2 rows\n",
    "r = torch.split(v, 2, 0)\n",
    "print(r,'\\n')\n",
    "\n",
    "#Split every 2 columns\n",
    "r = torch.split(v, 2, 1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Select, Mask Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  2],\n",
      "        [ 5,  7],\n",
      "        [10, 12],\n",
      "        [15, 17],\n",
      "        [20, 22]]) \n",
      "\n",
      "tensor([[ 0,  2],\n",
      "        [ 5,  7],\n",
      "        [10, 12],\n",
      "        [15, 17],\n",
      "        [20, 22]]) \n",
      "\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [10, 11, 12, 13, 14]])\n"
     ]
    }
   ],
   "source": [
    "#INDEX SELECT\n",
    "\"\"\"\n",
    "index_select(input, dim, index, out=None) -> Tensor\n",
    "\n",
    "Returns a new tensor which indexes the :attr:`input` tensor \n",
    "along dimension :attr:`dim` using the entries in :attr:`index` \n",
    "which is a `LongTensor`.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#torch.INDEX_SELECT(tensor, dim, index)\n",
    "indx = torch.LongTensor([0,2])\n",
    "r = torch.index_select(v, 1, indx) #Same as v[:,[0,2]] (columns)\n",
    "\n",
    "print(v[:,[0,2]], '\\n')\n",
    "print(r,'\\n')\n",
    "\n",
    "r = torch.index_select(v, 0, indx)\n",
    "print(r) # same as v[[0,2],:]   (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False],\n",
      "        [False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True]]) \n",
      "\n",
      "tensor([ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\n"
     ]
    }
   ],
   "source": [
    "#MASK SELECT\n",
    "\"\"\"\n",
    "masked_select(input, mask, out=None) -> Tensor\n",
    "\n",
    "Returns a new 1-D tensor which indexes the :attr:`input` tensor \n",
    "according to the boolean mask :attr:`mask` which is a `BoolTensor`.\n",
    "\"\"\"\n",
    "\n",
    "mask = v.ge(9) #same as v>=3\n",
    "print(mask, '\\n')\n",
    "r = torch.masked_select(v, mask) # same as v[mask]\n",
    "\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQUEEZE ~ REMOVE UNNECESSARY DIMENSIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.]]]]) torch.Size([2, 1, 1, 2]) \n",
      "\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(2,1,1,2)\n",
    "print(t, t.shape,'\\n')\n",
    "\n",
    "\"\"\"\n",
    "squeeze(input, dim=None, out=None) -> Tensor\n",
    "\n",
    "Returns a tensor with all the dimensions of `input` \n",
    "of size `1` removed.\n",
    "\"\"\"\n",
    "\n",
    "t = torch.squeeze(t)\n",
    "print(t, t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNSQUEEZE ~ X dimension tensor to X+1 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.]) torch.Size([3])\n",
      "tensor([[1., 2., 3.]]) torch.Size([1, 3])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "#ADD EXTRA DIMENSIONS\n",
    "t = torch.Tensor([1,2,3])\n",
    "print(t, t.shape)\n",
    "\n",
    "\"\"\"\n",
    "unsqueeze(input, dim, out=None) -> Tensor\n",
    "\n",
    "Returns a new tensor with a dimension of size one inserted at the\n",
    "specified position.\n",
    "\"\"\"\n",
    "\n",
    "#current dim is (3)\n",
    "#can insert a dimension at 0 -> (1,3)\n",
    "r = torch.unsqueeze(t,0)\n",
    "print(r, r.shape)\n",
    "\n",
    "#or insert dimension at 1 -> (3,1)\n",
    "r = torch.unsqueeze(t,1)\n",
    "print(r, r.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]]) \n",
      "\n",
      "tensor([[ 0,  5, 10, 15, 20],\n",
      "        [ 1,  6, 11, 16, 21],\n",
      "        [ 2,  7, 12, 17, 22],\n",
      "        [ 3,  8, 13, 18, 23],\n",
      "        [ 4,  9, 14, 19, 24]])\n"
     ]
    }
   ],
   "source": [
    "print(v,'\\n')\n",
    "\n",
    "\"\"\"\n",
    "transpose(input, dim0, dim1) -> Tensor\n",
    "\n",
    "Returns a tensor that is a transposed version of :attr:`input`.\n",
    "The given dimensions :attr:`dim0` and :attr:`dim1` are swapped.\n",
    "\n",
    "The resulting :attr:`out` tensor shares it's underlying storage with the\n",
    ":attr:`input` tensor, so changing the content of one would change the content\n",
    "of the other.\n",
    "\"\"\"\n",
    "\n",
    "print(torch.transpose(v, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNBIND ~ Remove a Tensor Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 10, 15, 20]),\n",
       " tensor([ 1,  6, 11, 16, 21]),\n",
       " tensor([ 2,  7, 12, 17, 22]),\n",
       " tensor([ 3,  8, 13, 18, 23]),\n",
       " tensor([ 4,  9, 14, 19, 24]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "unbind(input, dim=0) -> seq\n",
    "\n",
    "Removes a tensor dimension.\n",
    "\n",
    "Returns a tuple of all slices along a given dimension, \n",
    "already without it.\n",
    "\"\"\"\n",
    "\n",
    "r = torch.unbind(v,1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([1, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  5, 10, 15, 20],\n",
       "        [ 1,  6, 11, 16, 21],\n",
       "        [ 2,  7, 12, 17, 22],\n",
       "        [ 3,  8, 13, 18, 23],\n",
       "        [ 4,  9, 14, 19, 24]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r[0].shape)\n",
    "#READD THE DIMENSION\n",
    "r = [torch.unsqueeze(i,0) for i in r]\n",
    "print(r[0].shape)\n",
    "\n",
    "#RECOMBINE ONF NEW DIMENSION\n",
    "torch.cat(r,dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution\n",
    "\n",
    "## Fill a Tensor with randomized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIFORM:  tensor([[0.7576, 0.2793, 0.4031],\n",
      "        [0.7347, 0.0293, 0.7999],\n",
      "        [0.3971, 0.7544, 0.5695]]) \n",
      "\n",
      "UNIFORM (discrete):  tensor([[2., 8., 9.],\n",
      "        [6., 3., 3.],\n",
      "        [0., 2., 1.]]) \n",
      "\n",
      "BERNOULLI:  tensor([[1., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.]]) \n",
      "\n",
      "NORMAL:  tensor([[ 0.0436,  1.3240, -0.1005],\n",
      "        [ 0.6443,  0.5244,  1.0157],\n",
      "        [ 0.2571, -0.9013,  0.8138]]) \n",
      "\n",
      "EXPONENTIAL:  tensor([[0.1522, 0.3676, 0.0485],\n",
      "        [0.0577, 0.1941, 0.8243],\n",
      "        [0.0975, 0.0281, 0.2311]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SET SEED\n",
    "torch.manual_seed(1)\n",
    "\n",
    "#Fill w/ UNIFORM continuous random variables (range 0,1)\n",
    "r = torch.Tensor(3,3).uniform_(0, to=1) #torch.rand\n",
    "print(\"UNIFORM: \",r,'\\n')\n",
    "\n",
    "#Fill w/ UNIFORM discrete rv\n",
    "r= torch.Tensor(3,3).random_(0,10)\n",
    "print(\"UNIFORM (discrete): \",r,'\\n')\n",
    "\n",
    "## Size: 2x2. Bernoulli with probability p stored in elements of r\n",
    "r = torch.Tensor(3,3).bernoulli_(p=0.5)\n",
    "print(\"BERNOULLI: \",r,'\\n')\n",
    "\n",
    "#NORMAL   torch.randn()\n",
    "r = torch.Tensor(3,3).normal_(mean=0, std=1)\n",
    "print(\"NORMAL: \",r,'\\n')\n",
    "\n",
    "#EXPONENTIAL\n",
    "r = torch.Tensor(3,3).exponential_(lambd=1)\n",
    "print(\"EXPONENTIAL: \",r,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise Operations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pointwise Ops\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    ".. autofunction:: abs\n",
    ".. autofunction:: acos           - arc cosine\n",
    ".. autofunction:: add\n",
    ".. autofunction:: addcdiv        - element wise: t1 + s * t2/t3\n",
    ".. autofunction:: addcmul        - element wise: t1 + s * t2 * t3\n",
    ".. autofunction:: asin           - arc sin\n",
    ".. autofunction:: atan\n",
    ".. autofunction:: atan2\n",
    ".. autofunction:: ceil           - ceiling\n",
    ".. autofunction:: clamp          - clamp elements into a range\n",
    ".. autofunction:: cos\n",
    ".. autofunction:: cosh\n",
    ".. autofunction:: div            - divide\n",
    ".. autofunction:: erf            - Gaussian error functiom\n",
    ".. autofunction:: erfinv         - Inverse\n",
    ".. autofunction:: exp\n",
    ".. autofunction:: expm1          - exponential of each element minus 1\n",
    ".. autofunction:: floor          \n",
    ".. autofunction:: fmod           - element wise remainder of division\n",
    ".. autofunction:: frac           - fraction part 3.4 -> 0.4\n",
    ".. autofunction:: lerp           - linear interpolation\n",
    ".. autofunction:: log            - natural log\n",
    ".. autofunction:: log1p          - y = log(1 + x)\n",
    ".. autofunction:: mul            - multiple\n",
    ".. autofunction:: neg \n",
    ".. autofunction:: pow\n",
    ".. autofunction:: reciprocal     - 1/x\n",
    ".. autofunction:: remainder      - remainder of division\n",
    ".. autofunction:: round\n",
    ".. autofunction:: rsqrt          - the reciprocal of the square-root \n",
    ".. autofunction:: sigmoid        - sigmode(x)\n",
    ".. autofunction:: sign\n",
    ".. autofunction:: sin\n",
    ".. autofunction:: sinh\n",
    ".. autofunction:: sqrt\n",
    ".. autofunction:: tan\n",
    ".. autofunction:: tanh\n",
    ".. autofunction:: trunc          - truncated integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3969,  0.4049,  0.3415, -0.3499, -0.2344],\n",
      "        [-0.5452,  0.2751, -1.1834,  1.7359, -0.5309],\n",
      "        [ 0.9356, -0.8873,  0.5298,  0.2684,  0.3501],\n",
      "        [-0.2723,  1.0666,  0.7679, -0.3329, -0.9173],\n",
      "        [ 0.8372,  1.4950, -0.8303, -1.9901, -0.8779]]) \n",
      "\n",
      "CLAMP:  tensor([[-0.3969,  0.4049,  0.3415, -0.3499, -0.2344],\n",
      "        [-0.5000,  0.2751, -0.5000,  0.5000, -0.5000],\n",
      "        [ 0.5000, -0.5000,  0.5000,  0.2684,  0.3501],\n",
      "        [-0.2723,  0.5000,  0.5000, -0.3329, -0.5000],\n",
      "        [ 0.5000,  0.5000, -0.5000, -0.5000, -0.5000]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.,  0.,  0., -0., -0.],\n",
       "        [-0.,  0., -1.,  1., -0.],\n",
       "        [ 0., -0.,  0.,  0.,  0.],\n",
       "        [-0.,  1.,  0., -0., -0.],\n",
       "        [ 0.,  1., -0., -1., -0.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.Tensor(5,5).normal_(0,1)\n",
    "print(r,'\\n')\n",
    "\n",
    "#ABS VALUES\n",
    "torch.abs(r)\n",
    "\n",
    "#ADD SCALAR\n",
    "torch.add(r, 10)\n",
    "\n",
    "#CLAMP TO RANGE [min, max] #will round up\n",
    "print(\"CLAMP: \",torch.clamp(r,-0.5,0.5),'\\n')\n",
    "\n",
    "#RECIPROCAL\n",
    "torch.reciprocal(r)\n",
    "\n",
    "#EXPONENTIAL\n",
    "torch.exp(r)\n",
    "\n",
    "#NATURAL LOG\n",
    "torch.log(r)\n",
    "\n",
    "#Take power of each element in tensor\n",
    "torch.pow(r, 2)\n",
    "\n",
    "#SIGMOID\n",
    "torch.sigmoid(r)\n",
    "\n",
    "#SQRT\n",
    "torch.sqrt(r)\n",
    "\n",
    "#TRUNCATE TO INTEGER\n",
    "torch.trunc(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 1.1250, 2.2500],\n",
      "        [3.3750, 4.5000, 5.6250],\n",
      "        [6.7500, 7.8750, 9.0000]]) \n",
      "\n",
      "SUM tensor([[ 3.3750],\n",
      "        [13.5000],\n",
      "        [23.6250]]) \n",
      "\n",
      "CUMSUM tensor([[ 0.0000,  1.1250,  3.3750],\n",
      "        [ 3.3750,  7.8750, 13.5000],\n",
      "        [ 6.7500, 14.6250, 23.6250]]) \n",
      "\n",
      "PRODUCT tensor([[  0.0000],\n",
      "        [ 85.4297],\n",
      "        [478.4062]]) \n",
      "\n",
      "MEAN tensor([[1.1250],\n",
      "        [4.5000],\n",
      "        [7.8750]]) \n",
      "\n",
      "VARIANCE tensor([[1.2656],\n",
      "        [1.2656],\n",
      "        [1.2656]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "v = torch.linspace(0,9,9).view(3,3)\n",
    "print(v,'\\n')\n",
    "\n",
    "#Sum along dimension\n",
    "print(\"SUM\", torch.sum(v,1,keepdim=True),'\\n') #sum rows\n",
    "\n",
    "#Adds at each element in tensor.\n",
    "print(\"CUMSUM\", torch.cumsum(v, 1),'\\n')\n",
    "\n",
    "#product\n",
    "print(\"PRODUCT\", torch.prod(v, 1, keepdim=True),'\\n')\n",
    "\n",
    "#mean of rows\n",
    "print(\"MEAN\", torch.mean(v,1,keepdim=True),'\\n')\n",
    "\n",
    "#variance\n",
    "print(\"VARIANCE\", torch.var(v,1,keepdim=True),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix - Vector Mutiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplying two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.)\n"
     ]
    }
   ],
   "source": [
    "#Dot product of 2 tensors\n",
    "\"\"\"\n",
    "dot(input, tensor) -> Tensor\n",
    "\n",
    "Computes the dot product (inner product) of two tensors. 1D\n",
    "\"\"\"\n",
    "r = torch.dot(torch.Tensor([4,2]),torch.Tensor([3,1]))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplying a Matrix and a Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matrix - Vector Products\n",
    "mat = torch.arange(8).view(2,4)\n",
    "vec = torch.arange(4)\n",
    "print(mat, mat.shape, '\\n')\n",
    "print(vec, vec.shape,'\\n')\n",
    "\n",
    "r = torch.mv(mat, vec) #similar to dot product\n",
    "print(r,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.arange(8).view(2,4)\n",
    "vec = torch.arange(4)\n",
    "print(mat, mat.shape, '\\n')\n",
    "print(vec, vec.shape,'\\n')\n",
    "\n",
    "r = torch.mvadd(mat, vec) #similar to dot product\n",
    "print(r,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]]) torch.Size([2, 4]) \n",
      "\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]]) torch.Size([4, 1]) \n",
      "\n",
      "tensor([[14],\n",
      "        [38]]) torch.Size([2, 1]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = torch.unsqueeze(vec,1)\n",
    "print(mat, mat.shape, '\\n')\n",
    "print(vec, vec.shape,'\\n')\n",
    "\n",
    "r = torch.mm(mat, vec) #similar to dot product\n",
    "print(r,r.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
