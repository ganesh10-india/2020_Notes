{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch NN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T18:29:41.567278Z",
     "start_time": "2019-10-19T18:29:40.608625Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _print(val):\n",
    "    print(val, val.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:02:32.988593Z",
     "start_time": "2019-10-18T02:02:32.759958Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:02:35.113811Z",
     "start_time": "2019-10-18T02:02:34.013033Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:02:35.137787Z",
     "start_time": "2019-10-18T02:02:34.724Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:02:36.034830Z",
     "start_time": "2019-10-18T02:02:35.307318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25d4cfcd470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(x_train[0].reshape(-1,28,28).squeeze(), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:02:43.437644Z",
     "start_time": "2019-10-18T02:02:43.339871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "tensor([5, 0, 4,  ..., 8, 4, 8]) tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, \n",
    "                                       (x_train, y_train, x_valid, y_valid))\n",
    "print(x_train.shape)\n",
    "print(y_train, y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation log_softmax\n",
    "\n",
    "LogSoftMax works better than regular SoftMax? [link](https://discuss.pytorch.org/t/logsoftmax-vs-softmax/21386/2)\n",
    "\n",
    "The point is, even though logsoftmax and softmax are monotonic, their effect on the relative values of the loss function changes. Using the log-softmax will punish bigger mistakes in likelihood space higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:04:42.999850Z",
     "start_time": "2019-10-18T02:04:42.985333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n",
      "torch.Size([3, 10]) \n",
      "\n",
      "tensor([ 0.7441, -4.9573,  0.6557,  4.8720, -6.0488,  4.6307, -1.1482,  0.2511,\n",
      "         1.4903, -0.5320], grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor([ 0.4224, -4.6121,  0.7242,  4.6341, -5.9888,  5.7190, -1.2207,  0.8001,\n",
      "         0.2427, -0.7631], grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor([[ 6.0292],\n",
      "        [11.3561],\n",
      "        [ 4.8723]], grad_fn=<UnsqueezeBackward0>) \n",
      "\n",
      "tensor([ -5.6069, -10.6414,  -5.3051,  -1.3951, -12.0181,  -0.3102,  -7.2499,\n",
      "         -5.2292,  -5.7866,  -6.7923], grad_fn=<SelectBackward>)\n",
      "tensor([5, 0, 4])\n",
      "tensor([5, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "xb = x_train[:3]\n",
    "yb = y_train[:3]\n",
    "print(xb.shape)\n",
    "print(xb.mm(weights).shape,'\\n')\n",
    "print(xb.mm(weights)[0],'\\n')\n",
    "print(xb.mm(weights)[0]+bias,'\\n')\n",
    "xb = xb.mm(weights)+bias\n",
    "print(xb.exp().sum(-1).log().unsqueeze(-1),'\\n')\n",
    "print((xb - xb.exp().sum(-1).log().unsqueeze(-1))[0])\n",
    "pred = xb - xb.exp().sum(-1).log().unsqueeze(-1)\n",
    "print(torch.argmax(pred, 1))\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:04:43.458613Z",
     "start_time": "2019-10-18T02:04:43.449664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "torch.Size([784, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#Activation function Outputs log-probabilities\n",
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb.mm(weights) + bias)\n",
    "\n",
    "#Xavier Initialization\n",
    "weights = torch.randn(784,10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10)\n",
    "bias.requires_grad_()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(weights.shape)\n",
    "print(bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative log loss\n",
    "\n",
    "Log loss (related to cross entropy mesures performance of classification where prediction input is a prob value between 0 and 1. Perfect model should have log loss 0. \n",
    "\n",
    "Log loss increases as predicted prob diverges from actual label.\n",
    "\n",
    "<img src=http://wiki.fast.ai/images/math/8/a/a/8aa1e513366a2046bee816f7a0f8dd1c.png>\n",
    "\n",
    "Note that y=0 if incorrect class\n",
    "\n",
    "Since the activation function was log_softmax, we dot have to take the log of the activation again. Just take the negative activation of the True class for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:05:13.551662Z",
     "start_time": "2019-10-18T02:05:13.545673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:05:41.707654Z",
     "start_time": "2019-10-18T02:05:41.701757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yb = y_train[:batch_size]\\nprint(accuracy(pred,yb))\\nprint(nll(preds,yb))'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]),target].mean()\n",
    "\n",
    "def accuracy(input, target):\n",
    "    p = torch.argmax(input, dim=1)\n",
    "    return (p==target).float().mean()\n",
    "\n",
    "\"\"\"yb = y_train[:batch_size]\n",
    "print(accuracy(pred,yb))\n",
    "print(nll(preds,yb))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:05:44.827621Z",
     "start_time": "2019-10-18T02:05:44.792303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3102, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-8865740f2743>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# grab the log-prob of correct class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#this is neg_log_loss for each example ->\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#average them for cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "print(-pred[0].max())\n",
    "# grab the log-prob of correct class\n",
    "print(-pred[range(yb.shape[0]),yb])\n",
    "#this is neg_log_loss for each example -> \n",
    "#average them for cost\n",
    "print(-pred[range(yb.shape[0]),yb].mean())\n",
    "#want to maximize this number -> make correct class as\n",
    "#large as possible\n",
    "\n",
    "#How does this work? seems like signs are wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the gradients to zero, so that we are ready for the next loop. Otherwise, our gradients would record a running tally of all the operations that had happened (i.e. loss.backward() adds the gradients to whatever is already stored, rather than replacing them).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:07:14.341333Z",
     "start_time": "2019-10-18T02:06:36.033495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "#Xavier Initialization\n",
    "weights = torch.randn(784,10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10)\n",
    "bias.requires_grad_()\n",
    "\n",
    "\n",
    "epochs = 50 # each epoch goes over the entire training set\n",
    "batch_size = 64\n",
    "lr = 0.01\n",
    "n = x_train.shape[0]\n",
    "\n",
    "loss_hist = []\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//batch_size): # // ~ int division\n",
    "        start = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "\n",
    "        xb, yb = x_train[start:end], y_train[start:end]\n",
    "        pred = model(xb)\n",
    "        loss = nll(pred, yb)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad(): #no_grad so we can do an in-place operation on a leaf node\n",
    "            weights -= lr*weights.grad\n",
    "            bias -= lr*bias.grad\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "    loss_hist.append(loss.data.item())\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.plot(range(len(loss_hist)),loss_hist) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:07:14.656565Z",
     "start_time": "2019-10-18T02:07:14.640503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2802, grad_fn=<NegBackward>)\n",
      "tensor(0.9211)\n"
     ]
    }
   ],
   "source": [
    "pred = model(x_valid)\n",
    "print(nll(pred, y_valid))\n",
    "print(accuracy(pred, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factoring with torch.nn\n",
    "Either make your code shorter, more understandable, or more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:07:14.888290Z",
     "start_time": "2019-10-18T02:07:14.882742Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "#combines neg-log-likelihood loss and log-softmax\n",
    "loss_func = F.cross_entropy\n",
    "def model(xb):\n",
    "    return xb.mm(weights)+bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package the model into a Class\n",
    "Use nn.Module and nn.Parameter . Create a class that holds weights and methords for forward and backward prop.\n",
    "\n",
    "nn.Module has a number of attributes and methods (such as .parameters() and .zero_grad()) which we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:07:15.061285Z",
     "start_time": "2019-10-18T02:07:15.056039Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784,10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "        return None\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return xb.mm(self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with model.parameters() and model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:07:36.390875Z",
     "start_time": "2019-10-18T02:07:36.382867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0597, -0.0197,  0.0201,  ...,  0.0039, -0.0627,  0.0058],\n",
      "        [-0.0211, -0.0283, -0.0180,  ..., -0.0046, -0.0135,  0.0162],\n",
      "        [ 0.0199,  0.0144, -0.0121,  ..., -0.0021,  0.0103, -0.0513],\n",
      "        ...,\n",
      "        [ 0.0355,  0.0428, -0.0355,  ..., -0.0044,  0.0119,  0.0456],\n",
      "        [-0.0001, -0.0549, -0.0634,  ...,  0.0794,  0.0762,  0.0046],\n",
      "        [ 0.0455,  0.0297,  0.0243,  ...,  0.0222, -0.0531,  0.0072]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "for param in model.parameters():\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:08:07.018247Z",
     "start_time": "2019-10-18T02:07:36.669418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def fit():\n",
    "    loss_hist = []\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//batch_size): # // ~ int division\n",
    "            start = i * batch_size\n",
    "            end = (i + 1) * batch_size\n",
    "\n",
    "            xb, yb = x_train[start:end], y_train[start:end]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): #Update all weights at once\n",
    "                    p -= lr*p.grad\n",
    "                model.zero_grad()   #zero out gradients for all parameters\n",
    "        loss_hist.append(loss.data.item())\n",
    "        \n",
    "    return loss_hist\n",
    "    \n",
    "loss_hist = fit()\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.plot(range(len(loss_hist)),loss_hist) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With nn.Linear\n",
    "[link](https://pytorch.org/tutorials/beginner/nn_tutorial.html#refactor-using-nn-linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:08:07.210271Z",
     "start_time": "2019-10-18T02:08:07.203240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:08:07.390280Z",
     "start_time": "2019-10-18T02:08:07.385292Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784,10)  #no need to initialize weights\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With optim\n",
    "instead of `p -= p.grad * lr`, use `torch.optim` to calculate an optimal step for rach batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:08:12.732212Z",
     "start_time": "2019-10-18T02:08:07.574101Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "epochs = 10\n",
    "bs = 64\n",
    "lr = 0.01\n",
    "\n",
    "model = Model()\n",
    "loss_func = F.cross_entropy\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        #update parameters automatically based on gradients\n",
    "        opt.step()  \n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Dataset\n",
    "\n",
    "PyTorch’s `TensorDataset` is a Dataset wrapping tensors. By defining a length and way of indexing, this also gives us a way to iterate, index, and slice along the first dimension of a tensor. This will make it easier to access both the independent and dependent variables in the same line as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:12:59.964668Z",
     "start_time": "2019-10-18T02:12:54.814885Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train) #smoosh that data together\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs: i * bs + bs] #iterate in one line\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:13:18.365462Z",
     "start_time": "2019-10-18T02:13:00.233821Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, \n",
    "                      batch_size=bs,\n",
    "                     shuffle=True)\n",
    "for epoch in range(epochs):\n",
    "    for xb,yb in train_dl: #easy iteration through your dataset\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Validation\n",
    "\n",
    "In section 1, we were just trying to get a reasonable training loop set up for use on our training data. In reality, you always should also have a __validation set__, in order to identify if you are overfitting.\n",
    "\n",
    "__Shuffling the training data__ is important to prevent correlation between batches and overfitting. On the other hand, the validation loss will be identical whether we shuffle the validation set or not. Since shuffling takes extra time, it makes no sense to shuffle the validation data.\n",
    "\n",
    "We’ll use a batch size for the validation set that is twice as large as that for the training set. This is because the __validation set does not need backpropagation and thus takes less memory__ (it doesn’t need to store the gradients). We take advantage of this to use a larger batch size and compute the loss more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:14:19.161730Z",
     "start_time": "2019-10-18T02:13:18.649954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)\n",
    "\n",
    "epochs = 30\n",
    "model = Model()\n",
    "loss_func = F.cross_entropy\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train_loss =[]\n",
    "val_loss = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb,yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    train_loss.append(loss.item())\n",
    "    model.eval() #call this to keep models like batchnorm and dropout \n",
    "    with torch.no_grad():\n",
    "        valid = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)/(y_valid.shape[0]//bs)\n",
    "        val_loss.append(valid.item())\n",
    "\n",
    "plt.title(\"Training-Validation Loss\")\n",
    "plt.plot(range(len(train_loss)),train_loss) \n",
    "plt.plot(range(len(val_loss)),val_loss) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create helper functions\n",
    "\n",
    "[link](https://pytorch.org/tutorials/beginner/nn_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:20:49.842145Z",
     "start_time": "2019-10-18T02:19:47.182704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3389158097743988\n",
      "1 0.3067798109531403\n",
      "2 0.29315096558332443\n",
      "3 0.28442450717687606\n",
      "4 0.2801130482196808\n",
      "5 0.2775348304629326\n",
      "6 0.27625955839157107\n",
      "7 0.27282633156776426\n",
      "8 0.2709454197406769\n",
      "9 0.2699028342008591\n",
      "10 0.2673029819011688\n",
      "11 0.26685731422901154\n",
      "12 0.26715501942634584\n",
      "13 0.26514497152566907\n",
      "14 0.2663704557955265\n",
      "15 0.26351123942136767\n",
      "16 0.26445348378419875\n",
      "17 0.26294642906188964\n",
      "18 0.26230059801340105\n",
      "19 0.26210777661800383\n",
      "20 0.2611381888628006\n",
      "21 0.26052178966403006\n",
      "22 0.26141355090141294\n",
      "23 0.2642173074483872\n",
      "24 0.26045167765021326\n",
      "25 0.2590922660529614\n",
      "26 0.26138583382368086\n",
      "27 0.2592720721840858\n",
      "28 0.26183348557949065\n",
      "29 0.25875099403262136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_model():\n",
    "    model = Model()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)\n",
    "        \n",
    "        \n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:47:28.780977Z",
     "start_time": "2019-10-18T02:47:28.774792Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,16, kernel_size=3,stride=2,padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:49:04.833706Z",
     "start_time": "2019-10-18T02:47:29.387859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5522479145050049\n",
      "1 0.3980927963256836\n",
      "2 0.2782034362077713\n",
      "3 0.21448879919052125\n",
      "4 0.22370268186330794\n"
     ]
    }
   ],
   "source": [
    "model=CNN()\n",
    "opt=optim.SGD(model.parameters(), lr=0.03, momentum=0.9)\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:49:35.291544Z",
     "start_time": "2019-10-18T02:49:35.286586Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a custom layer\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:51:10.965413Z",
     "start_time": "2019-10-18T02:49:35.817193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6595972821235657\n",
      "1 0.3279928419113159\n",
      "2 0.2508931781232357\n",
      "3 0.21666518794894218\n",
      "4 0.27602433536946774\n",
      "tensor([3, 0, 4])\n",
      "tensor([5, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr=0.03\n",
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.3)\n",
    "fit(epochs,model,loss_func,opt,train_dl,valid_dl)\n",
    "\n",
    "print(torch.argmax(model(x_train[:3]), dim=1))\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T03:01:09.225633Z",
     "start_time": "2019-10-18T03:01:09.219432Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y): # the iterator gives X and y\n",
    "    return x.view(-1,1,28,28), y\n",
    "\n",
    "class WrappedDataLoader():\n",
    "    \"\"\"\n",
    "    Create a custom iterator that processes your dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "            \n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T03:02:45.355518Z",
     "start_time": "2019-10-18T03:01:09.478952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9293505615234375\n",
      "1 0.333184059882164\n",
      "2 0.2696040114879608\n",
      "3 0.2218672159910202\n",
      "4 0.231476465600729\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1), #adapts to the size of the image, outputs 1 dim\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T03:02:45.860208Z",
     "start_time": "2019-10-18T03:02:45.855221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T03:02:46.155115Z",
     "start_time": "2019-10-18T03:02:46.151293Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a device object to represent your GPU\n",
    "dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T03:11:49.660616Z",
     "start_time": "2019-10-18T03:11:08.113317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.2595356033325196\n",
      "1 1.642110375213623\n",
      "2 1.2932282413482665\n",
      "3 0.8977149812698364\n",
      "4 0.7996481155395507\n",
      "5 0.8012100366592407\n",
      "6 0.707154974269867\n",
      "7 0.5995462689399719\n",
      "8 0.7608398029327392\n",
      "9 0.4844808643341064\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1), #adapts to the size of the image, outputs 1 dim\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1,1,28,28).to(dev), y.to(dev)\n",
    "\n",
    "train_dl = DataLoader(train_ds,batch_size=bs,shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)\n",
    "\n",
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(),lr=0.03)\n",
    "fit(10, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing thoughts\n",
    "We now have a general data pipeline and training loop which you can use for training many types of models using Pytorch. To see how simple training a model can now be, take a look at the mnist_sample sample notebook.\n",
    "\n",
    "Of course, there are many things you’ll want to add, such as data augmentation, hyperparameter tuning, monitoring training, transfer learning, and so forth. These features are available in the fastai library, which has been developed using the same design approach shown in this tutorial, providing a natural next step for practitioners looking to take their models further.\n",
    "\n",
    "We promised at the start of this tutorial we’d explain through example each of torch.nn, torch.optim, Dataset, and DataLoader. So let’s summarize what we’ve seen:\n",
    "\n",
    "torch.nn\n",
    "\n",
    "Module: creates a callable which behaves like a function, but can also contain state(such as neural net layer weights). It knows what Parameter (s) it contains and can zero all their gradients, loop through them for weight updates, etc.\n",
    "\n",
    "Parameter: a wrapper for a tensor that tells a Module that it has weights that need updating during backprop. Only tensors with the requires_grad attribute set are updated\n",
    "\n",
    "functional: a module(usually imported into the F namespace by convention) which contains activation functions, loss functions, etc, as well as non-stateful versions of layers such as convolutional and linear layers.\n",
    "\n",
    "torch.optim: Contains optimizers such as SGD, which update the weights of Parameter during the backward step\n",
    "\n",
    "Dataset: An abstract interface of objects with a __len__ and a __getitem__, including classes provided with Pytorch such as TensorDataset\n",
    "\n",
    "DataLoader: Takes any Dataset and creates an iterator which returns batches of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Modules\n",
    "[link](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "\n",
    "### Three core functionalities\n",
    "1. `torch.save` - serialize an object to disk using pickle.\n",
    "2. `torch.load` - deserialize a file into an object\n",
    "3. `torch.nn.Module.load_save_dict` -Model has a parameter dictionary, this loads that parameter dict with a deserialized state_dict.\n",
    "\n",
    "### What is a `state dict`?\n",
    "Parameters are stored and can be accessed `model.parameters()`. State_dict is a Python dictionary that maps each layer to its parameter tensor. Only layers with learnable parameters are present in the state_dict. `torch.optim` objects also have a `state_dict`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:07:25.156276Z",
     "start_time": "2019-10-19T19:07:25.143795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state dict\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([100, 400])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([84, 100])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "\n",
      "Optiimizer state dict\n",
      "param_groups \t [{'nesterov': False, 'weight_decay': 0, 'lr': 0.001, 'dampening': 0, 'momentum': 0.9, 'params': [1965805366008, 1965805478248, 1965805478320, 1965805478104, 1965805367016, 1965805478896, 1965805478752, 1965805478680, 1965805478464, 1965805478968]}]\n",
      "state \t {}\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16, 5)\n",
    "        self.fc1 = nn.Linear(5*5*16,100)\n",
    "        self.fc2 = nn.Linear(100,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "\n",
    "print(\"Model's state dict\")\n",
    "for param in model.state_dict():\n",
    "    print(param, '\\t', model.state_dict()[param].size())\n",
    "print()\n",
    "\n",
    "print(\"Optiimizer state dict\")\n",
    "for param in optimizer.state_dict():\n",
    "    print(param, '\\t', optimizer.state_dict()[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:09:51.591378Z",
     "start_time": "2019-10-19T19:09:51.563334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0677,  0.0495, -0.1024, -0.0288,  0.0150],\n",
      "          [ 0.0089,  0.0648, -0.0243, -0.1149, -0.0608],\n",
      "          [-0.0073,  0.0856,  0.0961,  0.0575, -0.0908],\n",
      "          [ 0.0819, -0.0539, -0.0713, -0.0717, -0.1135],\n",
      "          [ 0.0187, -0.0606, -0.0438,  0.0182,  0.1140]],\n",
      "\n",
      "         [[-0.0478,  0.0610,  0.1071,  0.0622,  0.0474],\n",
      "          [-0.0730,  0.1031,  0.0523, -0.1106,  0.0753],\n",
      "          [ 0.0329,  0.0756, -0.0991, -0.0225,  0.0712],\n",
      "          [ 0.0546,  0.0377, -0.1027, -0.0913,  0.0827],\n",
      "          [-0.1059,  0.1057,  0.0868,  0.0855, -0.0582]],\n",
      "\n",
      "         [[ 0.0763, -0.0679, -0.0913,  0.0349,  0.0207],\n",
      "          [-0.0685, -0.0617,  0.0178,  0.0948,  0.0173],\n",
      "          [-0.0272, -0.0427, -0.0233, -0.0380,  0.1089],\n",
      "          [ 0.0600, -0.0861,  0.0348, -0.0092, -0.0611],\n",
      "          [-0.0331,  0.0114, -0.0381,  0.1013,  0.0244]]],\n",
      "\n",
      "\n",
      "        [[[-0.0183,  0.0002,  0.0252,  0.0493,  0.1008],\n",
      "          [ 0.1019,  0.1145,  0.0533, -0.0264, -0.0061],\n",
      "          [ 0.0525,  0.0838, -0.0589, -0.0818, -0.0882],\n",
      "          [ 0.0589, -0.0496,  0.0184,  0.1043,  0.0401],\n",
      "          [ 0.0805, -0.0861,  0.0942,  0.1091,  0.0974]],\n",
      "\n",
      "         [[ 0.0051, -0.0517,  0.0830, -0.0182,  0.0161],\n",
      "          [ 0.0405,  0.0920,  0.1044, -0.0109, -0.0623],\n",
      "          [ 0.0793, -0.0589,  0.0848, -0.0030, -0.0935],\n",
      "          [-0.0187,  0.0164,  0.0856,  0.0457,  0.0779],\n",
      "          [-0.0371, -0.0902, -0.0427, -0.1045, -0.0164]],\n",
      "\n",
      "         [[-0.0627, -0.0032, -0.0109, -0.0624, -0.0141],\n",
      "          [ 0.0293, -0.0453, -0.0561,  0.0284, -0.0869],\n",
      "          [ 0.0944, -0.0003, -0.0312,  0.0227, -0.0571],\n",
      "          [ 0.0801,  0.0366,  0.0655, -0.0944, -0.0213],\n",
      "          [-0.0137,  0.0252,  0.0397,  0.1100,  0.0105]]],\n",
      "\n",
      "\n",
      "        [[[-0.1099, -0.0535,  0.0056,  0.0513,  0.0099],\n",
      "          [ 0.0263,  0.0530, -0.0942, -0.0076, -0.0445],\n",
      "          [-0.0140, -0.0776,  0.0016, -0.1138, -0.0575],\n",
      "          [ 0.0886, -0.0986, -0.0267,  0.0300,  0.0383],\n",
      "          [-0.0226, -0.0444, -0.0706,  0.0969,  0.0489]],\n",
      "\n",
      "         [[-0.1101, -0.0540, -0.0375,  0.0541,  0.0799],\n",
      "          [ 0.0127, -0.0872,  0.0028,  0.0450, -0.0909],\n",
      "          [ 0.0355,  0.0117, -0.0119, -0.1005, -0.0240],\n",
      "          [-0.0632,  0.1091,  0.0540,  0.0001, -0.0891],\n",
      "          [ 0.0351, -0.0787,  0.0255, -0.0296,  0.1114]],\n",
      "\n",
      "         [[-0.0378, -0.0160,  0.0241,  0.0410,  0.0435],\n",
      "          [-0.0041,  0.0081,  0.0613,  0.0843, -0.0107],\n",
      "          [-0.0574,  0.1138,  0.0793,  0.0532, -0.0779],\n",
      "          [ 0.0719,  0.0569,  0.0875, -0.1127,  0.0943],\n",
      "          [ 0.0488,  0.0376, -0.0003, -0.0778,  0.0572]]],\n",
      "\n",
      "\n",
      "        [[[-0.0435,  0.0551,  0.0299, -0.0950, -0.0882],\n",
      "          [ 0.0527, -0.1051, -0.0035, -0.0343, -0.0459],\n",
      "          [ 0.1141,  0.0854,  0.1088, -0.0967,  0.0412],\n",
      "          [-0.0148,  0.0918,  0.0274,  0.1118, -0.0290],\n",
      "          [ 0.0862,  0.0996, -0.0650, -0.0802,  0.0623]],\n",
      "\n",
      "         [[-0.1128, -0.0129,  0.0975,  0.0956, -0.1096],\n",
      "          [-0.0404,  0.0453, -0.0062,  0.0635, -0.0200],\n",
      "          [ 0.0618, -0.0542, -0.0357, -0.1058, -0.1030],\n",
      "          [-0.0066,  0.1043, -0.0870, -0.0504, -0.0115],\n",
      "          [-0.0958, -0.0311,  0.0929, -0.1138, -0.0809]],\n",
      "\n",
      "         [[ 0.0477,  0.0633,  0.0313, -0.0580, -0.1102],\n",
      "          [-0.0353, -0.0650,  0.0518,  0.0291, -0.1095],\n",
      "          [-0.1146,  0.1151,  0.0644, -0.0883,  0.0020],\n",
      "          [-0.0515, -0.1086, -0.0821, -0.1019, -0.0097],\n",
      "          [ 0.0531,  0.0028, -0.0414, -0.0179,  0.1133]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0247, -0.0193,  0.0508, -0.0298, -0.0135],\n",
      "          [-0.0706, -0.1116,  0.0903, -0.0337, -0.0800],\n",
      "          [-0.1048, -0.0352, -0.0935,  0.0349,  0.1108],\n",
      "          [ 0.0704,  0.0522,  0.0402,  0.0724, -0.0194],\n",
      "          [ 0.0384,  0.0965,  0.0536, -0.0888, -0.0669]],\n",
      "\n",
      "         [[ 0.0215,  0.0564,  0.0973,  0.0736,  0.0222],\n",
      "          [-0.0414,  0.0227, -0.0771, -0.0450,  0.0592],\n",
      "          [ 0.0565, -0.0721,  0.0455, -0.0593, -0.0346],\n",
      "          [ 0.0490,  0.0318,  0.0067, -0.0965,  0.0933],\n",
      "          [ 0.0809,  0.0577,  0.0323, -0.0659,  0.0120]],\n",
      "\n",
      "         [[ 0.0388,  0.0307, -0.0260,  0.0541, -0.0375],\n",
      "          [ 0.0206, -0.0408, -0.0297, -0.0725, -0.0679],\n",
      "          [-0.0004,  0.0602, -0.0323, -0.0770, -0.0787],\n",
      "          [ 0.0428,  0.0183,  0.0716, -0.0009, -0.1043],\n",
      "          [-0.0257,  0.0359,  0.0734, -0.0499, -0.0208]]],\n",
      "\n",
      "\n",
      "        [[[-0.0617,  0.0079, -0.0380, -0.0305,  0.0946],\n",
      "          [-0.0045,  0.0835, -0.0842, -0.1050,  0.0358],\n",
      "          [ 0.0427, -0.0116,  0.1103,  0.0045,  0.0512],\n",
      "          [ 0.0916,  0.1074,  0.1009,  0.0173,  0.1001],\n",
      "          [ 0.0250,  0.0994, -0.0152,  0.0182, -0.0531]],\n",
      "\n",
      "         [[ 0.0145, -0.0267, -0.0792, -0.1118, -0.0600],\n",
      "          [-0.0504, -0.0199,  0.0320,  0.0730,  0.0647],\n",
      "          [ 0.0168, -0.0371, -0.0312, -0.0868,  0.1067],\n",
      "          [ 0.0197, -0.0408,  0.0284,  0.0649, -0.0301],\n",
      "          [ 0.0167,  0.0773, -0.1147,  0.0989, -0.0410]],\n",
      "\n",
      "         [[ 0.0086,  0.0629, -0.0226, -0.0522,  0.0201],\n",
      "          [-0.0048, -0.0743,  0.0506, -0.0271, -0.0113],\n",
      "          [-0.0662, -0.1096,  0.0228,  0.0245,  0.0919],\n",
      "          [ 0.1045,  0.0505, -0.0263,  0.0540, -0.0089],\n",
      "          [ 0.0331,  0.0226, -0.0386, -0.1130,  0.0732]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#print(model.state_dict()) dictionary with all parameters\n",
    "print()\n",
    "#print(model.parameters()) #python generator with \n",
    "start = True\n",
    "for i in model.parameters():\n",
    "    if start:\n",
    "        print(i)\n",
    "        start=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a model for inference\n",
    "Remember that you must call `model.eval()` to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:12:57.196100Z",
     "start_time": "2019-10-19T19:12:57.155528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model_state_dict.pkl')\n",
    "taco = Model()\n",
    "\n",
    "#takes dictionary object\n",
    "taco.load_state_dict(torch.load('model_state_dict.pkl'))\n",
    "taco.eval()   #ets the module in evaluation mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save load entire model\n",
    "This save/load process uses the most intuitive syntax and involves the least amount of code. Saving a model in this way will save the entire module using Python’s pickle module. The disadvantage of this approach is that the serialized data is bound to the specific classes and the exact directory structure used when the model is saved. The reason for this is because pickle does not save the model class itself. Rather, __it saves a path to the file containing the class, which is used during load time. Because of this, your code can break__ in various ways when used in other projects or after refactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, PATH)\n",
    "# Model class must be defined somewhere\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a general checkpoint for inference and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='model_state_dict.pkl'\n",
    "\n",
    "state = {\n",
    "    'epoch':epoch+1,\n",
    "    'state_dict':model.state_dict(),\n",
    "    'optim_dict':optimizer.state_dict(),\n",
    "}\n",
    "\n",
    "torch.save(state, PATH)\n",
    "\n",
    "\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# or\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Multiple Models in One File\n",
    "When saving a model comprised of multiple torch.nn.Modules, such as a GAN, a sequence-to-sequence model, or an ensemble of models, you follow the same approach as when you are saving a general checkpoint. In other words, save a dictionary of each model’s state_dict and corresponding optimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'modelA_state_dict': modelA.state_dict(),\n",
    "            'modelB_state_dict': modelB.state_dict(),\n",
    "            'optimizerA_state_dict': optimizerA.state_dict(),\n",
    "            'optimizerB_state_dict': optimizerB.state_dict(),\n",
    "            ...\n",
    "            }, PATH)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "modelA.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "modelB.load_state_dict(checkpoint['modelB_state_dict'])\n",
    "optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])\n",
    "\n",
    "modelA.eval()\n",
    "modelB.eval()\n",
    "# - or -\n",
    "modelA.train()\n",
    "modelB.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmstarting with params from a trained model\n",
    "\n",
    "Whether you are loading from a partial state_dict, which is missing some keys, or loading a state_dict with more keys than the model that you are loading into, you can set the strict argument to False in the `load_state_dict()` function to ignore non-matching keys.\n",
    "\n",
    "If you want to load parameters from one layer to another, but some keys do not match, simply change the name of the parameter keys in the state_dict that you are loading to match the keys in the model that you are loading into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelA.state_dict(), PATH)\n",
    "\n",
    "\n",
    "modelB = TheModelBClass(*args, **kwargs)\n",
    "modelB.load_state_dict(torch.load(PATH), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save on GPU, Load on GPU\n",
    "\n",
    "When loading a model on a GPU that was trained and saved on GPU, simply convert the initialized model to a CUDA optimized model using `model.to(torch.device('cuda'))`. Also, be sure to use the `.to(torch.device('cuda'))` function __on all model inputs__ to prepare the data for the model. Note that calling `my_tensor.to(device)` __returns a new copy of my_tensor on GPU__. It does NOT overwrite my_tensor. __Therefore, remember to manually overwrite tensors__: `my_tensor = my_tensor.to(torch.device('cuda'))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "#LOAD\n",
    "device = torch.device('cuda')\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_checkpoint(state,\n",
    "                     isbest=True,\n",
    "                     checkpoint='filepath')\n",
    "utils.load_checkpoint(restore_path, \n",
    "                      model, \n",
    "                      optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 50, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 26, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv2d(16,33,(3,5), \n",
    "              stride=(2,1), \n",
    "              padding = (4,2), \n",
    "              dilation=(3,1))\n",
    "input = Variable(torch.randn(20,16,50,100))\n",
    "print(input.shape)\n",
    "m(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.]]], dtype=torch.float64) torch.Size([1, 4, 4]) \n",
      "\n",
      "tensor([[[ 5.,  7.],\n",
      "         [13., 15.]]], dtype=torch.float64) torch.Size([1, 2, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Max Pooling - cuts the size in have by retaining only the max \n",
    "value in a subset of a matrix. Outputs a smaller matrix with\n",
    "the combined max values for the subcells.\n",
    "\n",
    "Reduces the number of parameters to learn and provides basic \n",
    " translation invariance to the internal representation.\n",
    "\"\"\"\n",
    "m = nn.MaxPool2d((2,2))\n",
    "x = torch.arange(16, dtype = torch.float64).reshape(-1,4).unsqueeze(0)\n",
    "pooled= m(x)\n",
    "_print(x)\n",
    "_print(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.5000,  4.5000],\n",
      "         [10.5000, 12.5000]]], dtype=torch.float64) torch.Size([1, 2, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.AvgPool2d(2)\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6745,  0.9691,  1.0134],\n",
      "        [-0.3971,  0.3070, -0.0195],\n",
      "        [ 0.0943, -0.8966,  0.7574]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(3,3))\n",
    "_print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.9691, 1.0134],\n",
      "        [0.0000, 0.3070, 0.0000],\n",
      "        [0.0943, 0.0000, 0.7574]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.ReLU()\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.7450e-03,  9.6910e-01,  1.0134e+00],\n",
      "        [-3.9710e-03,  3.0700e-01, -1.9512e-04],\n",
      "        [ 9.4303e-02, -8.9660e-03,  7.5740e-01]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.LeakyReLU()\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3375, 0.7249, 0.7337],\n",
      "        [0.4020, 0.5762, 0.4951],\n",
      "        [0.5236, 0.2897, 0.6808]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.Sigmoid()\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2234, 0.5986, 0.4695],\n",
      "        [0.2948, 0.3087, 0.1671],\n",
      "        [0.4819, 0.0927, 0.3634]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim=0)\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nn.BatchNorm1d(\n",
    "    num_features,\n",
    "    eps=1e-05,\n",
    "    momentum=0.1,\n",
    "    affine=True,\n",
    "    track_running_stats=True,\n",
    ")\n",
    "Docstring:     \n",
    "Applies Batch Normalization over a 2D or 3D input (a mini-batch of 1D\n",
    "inputs with optional additional channel dimension) as described in the paper\n",
    "`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`_ .\n",
    "\"\"\"\n",
    "\n",
    "nn.BatchNorm1d(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\"\"\"\n",
    "Applies a multi-layer Elman RNN with :math:`tanh` or :math:`ReLU` non-linearity to an\n",
    "input sequence.\n",
    "\n",
    "\n",
    "For each element in the input sequence, each layer computes the following\n",
    "function:\n",
    "\n",
    ".. math::\n",
    "    h_t = \\text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n",
    "\n",
    "where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is\n",
    "the input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the\n",
    "previous layer at time `t-1` or the initial hidden state at time `0`.\n",
    "If :attr:`nonlinearity` is ``'relu'``, then `ReLU` is used instead of `tanh`.\n",
    "\n",
    "Args:\n",
    "    input_size: The number of expected features in the input `x`\n",
    "    hidden_size: The number of features in the hidden state `h`\n",
    "    num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
    "        would mean stacking two RNNs together to form a `stacked RNN`,\n",
    "        with the second RNN taking in outputs of the first RNN and\n",
    "        computing the final results. Default: 1\n",
    "    nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n",
    "    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
    "        Default: ``True``\n",
    "    batch_first: If ``True``, then the input and output tensors are provided\n",
    "        as `(batch, seq, feature)`. Default: ``False``\n",
    "    dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
    "        RNN layer except the last layer, with dropout probability equal to\n",
    "        :attr:`dropout`. Default: 0\n",
    "    bidirectional: If ``True``, becomes a bidirectional RNN. Default: ``False``\n",
    "\n",
    "Inputs: input, h_0\n",
    "    - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features\n",
    "      of the input sequence. The input can also be a packed variable length\n",
    "      sequence. See :func:`torch.nn.utils.rnn.pack_padded_sequence`\n",
    "      or :func:`torch.nn.utils.rnn.pack_sequence`\n",
    "      for details.\n",
    "    - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the initial hidden state for each element in the batch.\n",
    "      Defaults to zero if not provided. If the RNN is bidirectional,\n",
    "      num_directions should be 2, else it should be 1.\n",
    "\n",
    "Outputs: output, h_n\n",
    "    - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor\n",
    "      containing the output features (`h_t`) from the last layer of the RNN,\n",
    "      for each `t`.  If a :class:`torch.nn.utils.rnn.PackedSequence` has\n",
    "      been given as the input, the output will also be a packed sequence.\n",
    "\n",
    "      For the unpacked case, the directions can be separated\n",
    "      using ``output.view(seq_len, batch, num_directions, hidden_size)``,\n",
    "      with forward and backward being direction `0` and `1` respectively.\n",
    "      Similarly, the directions can be separated in the packed case.\n",
    "    - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the hidden state for `t = seq_len`.\n",
    "\n",
    "      Like *output*, the layers can be separated using\n",
    "      ``h_n.view(num_layers, num_directions, batch, hidden_size)``.\n",
    "\n",
    "Shape:\n",
    "    - Input1: :math:`(L, N, H_{in})` tensor containing input features where\n",
    "      :math:`H_{in}=\\text{input\\_size}` and `L` represents a sequence length.\n",
    "    - Input2: :math:`(S, N, H_{out})` tensor\n",
    "      containing the initial hidden state for each element in the batch.\n",
    "      :math:`H_{out}=\\text{hidden\\_size}`\n",
    "      Defaults to zero if not provided. where :math:`S=\\text{num\\_layers} * \\text{num\\_directions}`\n",
    "      If the RNN is bidirectional, num_directions should be 2, else it should be 1.\n",
    "    - Output1: :math:`(L, N, H_{all})` where :math:`H_{all}=\\text{num\\_directions} * \\text{hidden\\_size}`\n",
    "    - Output2: :math:`(S, N, H_{out})` tensor containing the next hidden state\n",
    "      for each element in the batch\n",
    "\n",
    "Attributes:\n",
    "    weight_ih_l[k]: the learnable input-hidden weights of the k-th layer,\n",
    "        of shape `(hidden_size, input_size)` for `k = 0`. Otherwise, the shape is\n",
    "        `(hidden_size, num_directions * hidden_size)`\n",
    "    weight_hh_l[k]: the learnable hidden-hidden weights of the k-th layer,\n",
    "        of shape `(hidden_size, hidden_size)`\n",
    "    bias_ih_l[k]: the learnable input-hidden bias of the k-th layer,\n",
    "        of shape `(hidden_size)`\n",
    "    bias_hh_l[k]: the learnable hidden-hidden bias of the k-th layer,\n",
    "        of shape `(hidden_size)`\n",
    "\n",
    ".. note::\n",
    "    All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
    "    where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
    "\n",
    ".. include:: cudnn_persistent_rnn.rst\n",
    "\n",
    "Examples::\n",
    "\n",
    "    >>> rnn = nn.RNN(10, 20, 2)\n",
    "    >>> input = torch.randn(5, 3, 10)\n",
    "    >>> h0 = torch.randn(2, 3, 20)\n",
    "    >>> output, hn = rnn(input, h0)\n",
    "\"\"\"\n",
    "#nn.RNN(input_size, hidden_size, num_recurrent_layers, nonlinearity,)\n",
    "x = Variable(torch.randn(5,3,10))\n",
    "rnn = nn.RNN(10,20,2)\n",
    "h0 = Variable(torch.randn(2,3,20))\n",
    "out, hn = rnn(x, h0)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(10,20,2)\n",
    "c0 = Variable(torch.randn(2,3,20))\n",
    "out, hn = lstm(x,(h0,c0))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "gru = nn.GRU(10,20,2)\n",
    "out,hnn = gru(x, h0)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "nn.Linear(in_features, out_features, bias=True)\n",
    "Docstring:     \n",
    "Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
    "\n",
    "Args:\n",
    "    in_features: size of each input sample\n",
    "    out_features: size of each output sample\n",
    "\"\"\"\n",
    "x = Variable(torch.randn(128,20))\n",
    "m = nn.Linear(20,2)\n",
    "print(m(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000],\n",
       "        [-1.4435, -0.1157],\n",
       "        [ 0.0000, -2.5524],\n",
       "        [ 0.0000, -0.0000],\n",
       "        [ 2.6681, -1.1160]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zeroes out some of the values in the input tensor\n",
    "m = nn.Dropout(p=0.5)\n",
    "input = Variable(torch.randn(5, 2))\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0281, -0.1043, -0.9801],\n",
       "         [ 0.0454,  1.2075, -0.5769],\n",
       "         [ 0.0454,  1.2075, -0.5769]],\n",
       "\n",
       "        [[ 0.7194,  1.8701, -0.5869],\n",
       "         [ 0.8274,  0.9918,  0.6741],\n",
       "         [-1.0281, -0.1043, -0.9801]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the input is an integer that selects the embedding\n",
    "embedding = nn.Embedding(10,3)\n",
    "x = torch.tensor([[2,1,1],[3,5,2]], dtype = torch.long)\n",
    "embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "input1 = Variable(torch.randn(100, 128))\n",
    "input2 = Variable(torch.randn(100, 128))\n",
    "cos = nn.CosineSimilarity()\n",
    "print(cos(input1,input2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1297, grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.L1Loss()\n",
    "pred = Variable(torch.randn(1,10), requires_grad=True)\n",
    "target = Variable(torch.randn(1,10))\n",
    "print(loss(pred,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8602, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "print(loss(pred,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7376, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "target = Variable(torch.LongTensor(1).random_(5))\n",
    "target = Variable(torch.randint(5, (1,),dtype=torch.long))\n",
    "print(loss(pred,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1021, -2.0721, -1.0736, -0.4213,  1.4890],\n",
       "        [-0.1656, -0.0502, -1.2592, -0.7588, -0.2377],\n",
       "        [ 0.2969,  0.1076,  0.6622,  0.1856, -0.0085]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3,5)\n",
    "nn.init.normal(w) #operates inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
