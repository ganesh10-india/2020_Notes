{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch NN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _print(val):\n",
    "    print(val, val.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e806b65470>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(x_train[0].reshape(-1,28,28).squeeze(), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "tensor([5, 0, 4,  ..., 8, 4, 8]) tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, \n",
    "                                       (x_train, y_train, x_valid, y_valid))\n",
    "print(x_train.shape)\n",
    "print(y_train, y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation log_softmax\n",
    "\n",
    "LogSoftMax works better than regular SoftMax? [link](https://discuss.pytorch.org/t/logsoftmax-vs-softmax/21386/2)\n",
    "\n",
    "The point is, even though logsoftmax and softmax are monotonic, their effect on the relative values of the loss function changes. Using the log-softmax will punish bigger mistakes in likelihood space higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "torch.Size([784, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#Activation function Outputs log-probabilities\n",
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb.mm(weights) + bias)\n",
    "\n",
    "\n",
    "\n",
    "#Xavier Initialization\n",
    "weights = torch.randn(784,10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10)\n",
    "bias.requires_grad_()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(weights.shape)\n",
    "print(bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n",
      "torch.Size([3, 10]) \n",
      "\n",
      "tensor([ 0.8506, -4.5983,  0.6762,  4.9477, -6.0592,  4.6678, -1.0155,  0.1793,\n",
      "         1.5168, -0.6079], grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor([ 0.5322, -4.2668,  0.7402,  4.7284, -6.0082,  5.7624, -1.0864,  0.7272,\n",
      "         0.2620, -0.8336], grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor([[ 6.0849],\n",
      "        [11.4318],\n",
      "        [ 4.9742]], grad_fn=<UnsqueezeBackward0>) \n",
      "\n",
      "tensor([ -5.5527, -10.3517,  -5.3447,  -1.3565, -12.0931,  -0.3225,  -7.1713,\n",
      "         -5.3577,  -5.8229,  -6.9185], grad_fn=<SelectBackward>)\n",
      "tensor([5, 0, 4])\n",
      "tensor([5, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "xb = x_train[:3]\n",
    "yb = y_train[:3]\n",
    "print(xb.shape)\n",
    "print(xb.mm(weights).shape,'\\n')\n",
    "print(xb.mm(weights)[0],'\\n')\n",
    "print(xb.mm(weights)[0]+bias,'\\n')\n",
    "xb = xb.mm(weights)+bias\n",
    "print(xb.exp().sum(-1).log().unsqueeze(-1),'\\n')\n",
    "print((xb - xb.exp().sum(-1).log().unsqueeze(-1))[0])\n",
    "pred = xb - xb.exp().sum(-1).log().unsqueeze(-1)\n",
    "print(torch.argmax(pred, 1))\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative log loss\n",
    "\n",
    "Log loss (related to cross entropy mesures performance of classification where prediction input is a prob value between 0 and 1. Perfect model should have log loss 0. \n",
    "\n",
    "Log loss increases as predicted prob diverges from actual label.\n",
    "\n",
    "<img src=http://wiki.fast.ai/images/math/8/a/a/8aa1e513366a2046bee816f7a0f8dd1c.png>\n",
    "\n",
    "Note that y=0 if incorrect class\n",
    "\n",
    "Since the activation function was log_softmax, we dot have to take the log of the activation again. Just take the negative activation of the True class for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0469)\n",
      "tensor(2.4654, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]),target].mean()\n",
    "\n",
    "def accuracy(input, target):\n",
    "    p = torch.argmax(input, dim=1)\n",
    "    return (p==target).float().mean()\n",
    "\n",
    "yb = y_train[:batch_size]\n",
    "print(accuracy(pred,yb))\n",
    "print(nll(preds,yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3225, grad_fn=<NegBackward>)\n",
      "tensor([0.3225, 0.0006, 0.1621], grad_fn=<NegBackward>)\n",
      "tensor(0.1617, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(-pred[0].max())\n",
    "# grab the log-prob of correct class\n",
    "print(-pred[range(yb.shape[0]),yb])\n",
    "#this is neg_log_loss for each example -> \n",
    "#average them for cost\n",
    "print(-pred[range(yb.shape[0]),yb].mean())\n",
    "#want to maximize this number -> make correct class as\n",
    "#large as possible\n",
    "\n",
    "#How does this work? seems like signs are wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the gradients to zero, so that we are ready for the next loop. Otherwise, our gradients would record a running tally of all the operations that had happened (i.e. loss.backward() adds the gradients to whatever is already stored, rather than replacing them).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "#Xavier Initialization\n",
    "weights = torch.randn(784,10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10)\n",
    "bias.requires_grad_()\n",
    "\n",
    "\n",
    "epochs = 50 # each epoch goes over the entire training set\n",
    "batch_size = 64\n",
    "lr = 0.01\n",
    "n = x_train.shape[0]\n",
    "\n",
    "loss_hist = []\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//batch_size): # // ~ int division\n",
    "        start = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "\n",
    "        xb, yb = x_train[start:end], y_train[start:end]\n",
    "        pred = model(xb)\n",
    "        loss = nll(pred, yb)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad(): #no_grad so we can do an in-place operation on a leaf node\n",
    "            weights -= lr*weights.grad\n",
    "            bias -= lr*bias.grad\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "    loss_hist.append(loss.data.item())\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.plot(range(len(loss_hist)),loss_hist) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2794, grad_fn=<NegBackward>)\n",
      "tensor(0.9224)\n"
     ]
    }
   ],
   "source": [
    "pred = model(x_valid)\n",
    "print(nll(pred, y_valid))\n",
    "print(accuracy(pred, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factoring with torch.nn\n",
    "Either make your code shorter, more understandable, or more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "#combines neg-log-likelihood loss and log-softmax\n",
    "loss_func = F.cross_entropy\n",
    "def model(xb):\n",
    "    return xb.mm(weights)+bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package the model into a Class\n",
    "Use nn.Module and nn.Parameter . Create a class that holds weights and methords for forward and backward prop.\n",
    "\n",
    "nn.Module has a number of attributes and methods (such as .parameters() and .zero_grad()) which we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784,10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "        return None\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return xb.mm(self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with model.parameters() and model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0077, -0.0490, -0.0650,  ..., -0.0799, -0.0376,  0.0465],\n",
      "        [ 0.0032,  0.0115,  0.0170,  ...,  0.0832, -0.0065,  0.0299],\n",
      "        [ 0.0209, -0.0426,  0.0061,  ...,  0.0147,  0.0168, -0.0500],\n",
      "        ...,\n",
      "        [ 0.0304, -0.0111,  0.0396,  ..., -0.0030,  0.0064,  0.0461],\n",
      "        [ 0.0436,  0.0159, -0.0118,  ...,  0.0390, -0.0258, -0.0533],\n",
      "        [-0.1070, -0.0257, -0.0111,  ...,  0.0088,  0.0612, -0.0377]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3168,  0.3398,  0.0577, -0.2241,  0.0583,  1.0992, -0.0698,  0.5458,\n",
      "        -1.2579, -0.2323], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def fit():\n",
    "    loss_hist = []\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//batch_size): # // ~ int division\n",
    "            start = i * batch_size\n",
    "            end = (i + 1) * batch_size\n",
    "\n",
    "            xb, yb = x_train[start:end], y_train[start:end]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): #Update all weights at once\n",
    "                    p -= lr*p.grad\n",
    "                model.zero_grad()   #zero out gradients for all parameters\n",
    "        loss_hist.append(loss.data.item())\n",
    "        \n",
    "    return loss_hist\n",
    "    \n",
    "loss_hist = fit()\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.plot(range(len(loss_hist)),loss_hist) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With nn.Linear\n",
    "[link](https://pytorch.org/tutorials/beginner/nn_tutorial.html#refactor-using-nn-linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models in PyTorch\n",
    "Model can be definde by subclassing the torch.nn.Module class. Define the parameters, then define the forward propagation of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNetwork(nn.Module):\n",
    "    def __init(self):\n",
    "        super(myNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H_out)\n",
    "        self.linear2 = nn.Linear(H_out, D_out)\n",
    "    def forward(self, data):\n",
    "        out = F.relu(self.linear1(data))\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'epoch':epoch+1\n",
    "    'state_dict':model.state_dict()\n",
    "    'optim_dict':optimider.state_dict()\n",
    "}\n",
    "utils.save_checkpoint(state,\n",
    "                     isbest=True,\n",
    "                     checkpoint='filepath')\n",
    "utils.load_checkpoint(restore_path, \n",
    "                      model, \n",
    "                      optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 50, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 26, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv2d(16,33,(3,5), \n",
    "              stride=(2,1), \n",
    "              padding = (4,2), \n",
    "              dilation=(3,1))\n",
    "input = Variable(torch.randn(20,16,50,100))\n",
    "print(input.shape)\n",
    "m(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.]]], dtype=torch.float64) torch.Size([1, 4, 4]) \n",
      "\n",
      "tensor([[[ 5.,  7.],\n",
      "         [13., 15.]]], dtype=torch.float64) torch.Size([1, 2, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Max Pooling - cuts the size in have by retaining only the max \n",
    "value in a subset of a matrix. Outputs a smaller matrix with\n",
    "the combined max values for the subcells.\n",
    "\n",
    "Reduces the number of parameters to learn and provides basic \n",
    " translation invariance to the internal representation.\n",
    "\"\"\"\n",
    "m = nn.MaxPool2d((2,2))\n",
    "x = torch.arange(16, dtype = torch.float64).reshape(-1,4).unsqueeze(0)\n",
    "pooled= m(x)\n",
    "_print(x)\n",
    "_print(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.5000,  4.5000],\n",
      "         [10.5000, 12.5000]]], dtype=torch.float64) torch.Size([1, 2, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.AvgPool2d(2)\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6745,  0.9691,  1.0134],\n",
      "        [-0.3971,  0.3070, -0.0195],\n",
      "        [ 0.0943, -0.8966,  0.7574]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(3,3))\n",
    "_print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.9691, 1.0134],\n",
      "        [0.0000, 0.3070, 0.0000],\n",
      "        [0.0943, 0.0000, 0.7574]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.ReLU()\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.7450e-03,  9.6910e-01,  1.0134e+00],\n",
      "        [-3.9710e-03,  3.0700e-01, -1.9512e-04],\n",
      "        [ 9.4303e-02, -8.9660e-03,  7.5740e-01]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.LeakyReLU()\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3375, 0.7249, 0.7337],\n",
      "        [0.4020, 0.5762, 0.4951],\n",
      "        [0.5236, 0.2897, 0.6808]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.Sigmoid()\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2234, 0.5986, 0.4695],\n",
      "        [0.2948, 0.3087, 0.1671],\n",
      "        [0.4819, 0.0927, 0.3634]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim=0)\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nn.BatchNorm1d(\n",
    "    num_features,\n",
    "    eps=1e-05,\n",
    "    momentum=0.1,\n",
    "    affine=True,\n",
    "    track_running_stats=True,\n",
    ")\n",
    "Docstring:     \n",
    "Applies Batch Normalization over a 2D or 3D input (a mini-batch of 1D\n",
    "inputs with optional additional channel dimension) as described in the paper\n",
    "`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`_ .\n",
    "\"\"\"\n",
    "\n",
    "nn.BatchNorm1d(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\"\"\"\n",
    "Applies a multi-layer Elman RNN with :math:`tanh` or :math:`ReLU` non-linearity to an\n",
    "input sequence.\n",
    "\n",
    "\n",
    "For each element in the input sequence, each layer computes the following\n",
    "function:\n",
    "\n",
    ".. math::\n",
    "    h_t = \\text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n",
    "\n",
    "where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is\n",
    "the input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the\n",
    "previous layer at time `t-1` or the initial hidden state at time `0`.\n",
    "If :attr:`nonlinearity` is ``'relu'``, then `ReLU` is used instead of `tanh`.\n",
    "\n",
    "Args:\n",
    "    input_size: The number of expected features in the input `x`\n",
    "    hidden_size: The number of features in the hidden state `h`\n",
    "    num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
    "        would mean stacking two RNNs together to form a `stacked RNN`,\n",
    "        with the second RNN taking in outputs of the first RNN and\n",
    "        computing the final results. Default: 1\n",
    "    nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n",
    "    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
    "        Default: ``True``\n",
    "    batch_first: If ``True``, then the input and output tensors are provided\n",
    "        as `(batch, seq, feature)`. Default: ``False``\n",
    "    dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
    "        RNN layer except the last layer, with dropout probability equal to\n",
    "        :attr:`dropout`. Default: 0\n",
    "    bidirectional: If ``True``, becomes a bidirectional RNN. Default: ``False``\n",
    "\n",
    "Inputs: input, h_0\n",
    "    - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features\n",
    "      of the input sequence. The input can also be a packed variable length\n",
    "      sequence. See :func:`torch.nn.utils.rnn.pack_padded_sequence`\n",
    "      or :func:`torch.nn.utils.rnn.pack_sequence`\n",
    "      for details.\n",
    "    - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the initial hidden state for each element in the batch.\n",
    "      Defaults to zero if not provided. If the RNN is bidirectional,\n",
    "      num_directions should be 2, else it should be 1.\n",
    "\n",
    "Outputs: output, h_n\n",
    "    - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor\n",
    "      containing the output features (`h_t`) from the last layer of the RNN,\n",
    "      for each `t`.  If a :class:`torch.nn.utils.rnn.PackedSequence` has\n",
    "      been given as the input, the output will also be a packed sequence.\n",
    "\n",
    "      For the unpacked case, the directions can be separated\n",
    "      using ``output.view(seq_len, batch, num_directions, hidden_size)``,\n",
    "      with forward and backward being direction `0` and `1` respectively.\n",
    "      Similarly, the directions can be separated in the packed case.\n",
    "    - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the hidden state for `t = seq_len`.\n",
    "\n",
    "      Like *output*, the layers can be separated using\n",
    "      ``h_n.view(num_layers, num_directions, batch, hidden_size)``.\n",
    "\n",
    "Shape:\n",
    "    - Input1: :math:`(L, N, H_{in})` tensor containing input features where\n",
    "      :math:`H_{in}=\\text{input\\_size}` and `L` represents a sequence length.\n",
    "    - Input2: :math:`(S, N, H_{out})` tensor\n",
    "      containing the initial hidden state for each element in the batch.\n",
    "      :math:`H_{out}=\\text{hidden\\_size}`\n",
    "      Defaults to zero if not provided. where :math:`S=\\text{num\\_layers} * \\text{num\\_directions}`\n",
    "      If the RNN is bidirectional, num_directions should be 2, else it should be 1.\n",
    "    - Output1: :math:`(L, N, H_{all})` where :math:`H_{all}=\\text{num\\_directions} * \\text{hidden\\_size}`\n",
    "    - Output2: :math:`(S, N, H_{out})` tensor containing the next hidden state\n",
    "      for each element in the batch\n",
    "\n",
    "Attributes:\n",
    "    weight_ih_l[k]: the learnable input-hidden weights of the k-th layer,\n",
    "        of shape `(hidden_size, input_size)` for `k = 0`. Otherwise, the shape is\n",
    "        `(hidden_size, num_directions * hidden_size)`\n",
    "    weight_hh_l[k]: the learnable hidden-hidden weights of the k-th layer,\n",
    "        of shape `(hidden_size, hidden_size)`\n",
    "    bias_ih_l[k]: the learnable input-hidden bias of the k-th layer,\n",
    "        of shape `(hidden_size)`\n",
    "    bias_hh_l[k]: the learnable hidden-hidden bias of the k-th layer,\n",
    "        of shape `(hidden_size)`\n",
    "\n",
    ".. note::\n",
    "    All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
    "    where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
    "\n",
    ".. include:: cudnn_persistent_rnn.rst\n",
    "\n",
    "Examples::\n",
    "\n",
    "    >>> rnn = nn.RNN(10, 20, 2)\n",
    "    >>> input = torch.randn(5, 3, 10)\n",
    "    >>> h0 = torch.randn(2, 3, 20)\n",
    "    >>> output, hn = rnn(input, h0)\n",
    "\"\"\"\n",
    "#nn.RNN(input_size, hidden_size, num_recurrent_layers, nonlinearity,)\n",
    "x = Variable(torch.randn(5,3,10))\n",
    "rnn = nn.RNN(10,20,2)\n",
    "h0 = Variable(torch.randn(2,3,20))\n",
    "out, hn = rnn(x, h0)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(10,20,2)\n",
    "c0 = Variable(torch.randn(2,3,20))\n",
    "out, hn = lstm(x,(h0,c0))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "gru = nn.GRU(10,20,2)\n",
    "out,hnn = gru(x, h0)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "nn.Linear(in_features, out_features, bias=True)\n",
    "Docstring:     \n",
    "Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
    "\n",
    "Args:\n",
    "    in_features: size of each input sample\n",
    "    out_features: size of each output sample\n",
    "\"\"\"\n",
    "x = Variable(torch.randn(128,20))\n",
    "m = nn.Linear(20,2)\n",
    "print(m(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000],\n",
       "        [-1.4435, -0.1157],\n",
       "        [ 0.0000, -2.5524],\n",
       "        [ 0.0000, -0.0000],\n",
       "        [ 2.6681, -1.1160]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zeroes out some of the values in the input tensor\n",
    "m = nn.Dropout(p=0.5)\n",
    "input = Variable(torch.randn(5, 2))\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0281, -0.1043, -0.9801],\n",
       "         [ 0.0454,  1.2075, -0.5769],\n",
       "         [ 0.0454,  1.2075, -0.5769]],\n",
       "\n",
       "        [[ 0.7194,  1.8701, -0.5869],\n",
       "         [ 0.8274,  0.9918,  0.6741],\n",
       "         [-1.0281, -0.1043, -0.9801]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the input is an integer that selects the embedding\n",
    "embedding = nn.Embedding(10,3)\n",
    "x = torch.tensor([[2,1,1],[3,5,2]], dtype = torch.long)\n",
    "embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "input1 = Variable(torch.randn(100, 128))\n",
    "input2 = Variable(torch.randn(100, 128))\n",
    "cos = nn.CosineSimilarity()\n",
    "print(cos(input1,input2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1297, grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.L1Loss()\n",
    "pred = Variable(torch.randn(1,10), requires_grad=True)\n",
    "target = Variable(torch.randn(1,10))\n",
    "print(loss(pred,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8602, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "print(loss(pred,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7376, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "target = Variable(torch.LongTensor(1).random_(5))\n",
    "target = Variable(torch.randint(5, (1,),dtype=torch.long))\n",
    "print(loss(pred,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1021, -2.0721, -1.0736, -0.4213,  1.4890],\n",
       "        [-0.1656, -0.0502, -1.2592, -0.7588, -0.2377],\n",
       "        [ 0.2969,  0.1076,  0.6622,  0.1856, -0.0085]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3,5)\n",
    "nn.init.normal(w) #operates inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
