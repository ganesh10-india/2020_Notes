{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations\n",
    "https://jhui.github.io/2018/02/09/PyTorch-Basic-operations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.6284e-06, 5.2945e+22, 6.6471e+22],\n",
      "        [6.6757e-07, 3.4014e+21, 1.3235e-08]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(2,3)\n",
    "print(x) #float tensor of zeros size=(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "#OPERATION SYNTAX\n",
    "y = torch.rand(2,3)\n",
    "z1 = x + y  #operator overloading\n",
    "z2 = torch.add(x,y) #same as above\n",
    "print(z1==z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4634e-01, 5.2945e+22, 6.6471e+22],\n",
      "        [6.2352e-01, 3.4014e+21, 4.4754e-01]])\n"
     ]
    }
   ],
   "source": [
    "#INPLACE OPERATIONS\n",
    "#followed by \"_\"\n",
    "x.add_(y)  #add y to x in-place\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1463, 0.6235])\n",
      "tensor([1.4634e-01, 5.2945e+22, 6.6471e+22])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 0]) #all rows, first column \n",
    "print(x[0, :]) #all columns, first row\n",
    "\n",
    "#the first position in a slice is the outtermost dimension in\n",
    "# vector format (dim1, dim2, dim3) [dim1[dim2[dim3]],[dim2[dim3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#METADATA\n",
    "print(x.size()) #size of x\n",
    "print(torch.numel(x)) #num elements in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1019,  1.5297, -1.3579],\n",
      "        [ 0.2959,  0.3765,  0.7293]])\n",
      "tensor([[-1.1019,  1.5297, -1.3579,  0.2959,  0.3765,  0.7293]])\n",
      "tensor([[-1.1019,  1.5297],\n",
      "        [-1.3579,  0.2959],\n",
      "        [ 0.3765,  0.7293]])\n"
     ]
    }
   ],
   "source": [
    "#RESHAPING A TENSOR ~ .VIEW()\n",
    "x = torch.randn(2,3)\n",
    "y = x.view(1,6)\n",
    "z = x.view(3,-1)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1019,  1.5297, -1.3579,  0.2959,  0.3765,  0.7293]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(1,6)  # can also use reshape instead of view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Matrix Fill Tensor w/ 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[[[1.],\n",
      "          [1.]]],\n",
      "\n",
      "\n",
      "        [[[1.],\n",
      "          [1.]]]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "#IDENTITY MATRIX ~ torch.eye()\n",
    "identity = torch.eye(3) #3x3 identity\n",
    "print(identity)\n",
    "\n",
    "#Vector of ones ~ torch.ones()\n",
    "v = torch.ones(2,1,2,1)\n",
    "print(v)\n",
    "v = torch.ones_like(identity) #ones w same shape as identity\n",
    "print(v)\n",
    "\n",
    "#FILL ~ .fill_()\n",
    "v[1].fill_(2) #FILL Second row with 2's\n",
    "v[2].fill_(3)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tensors with Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([0, 2, 4])\n",
      "tensor([ 0.0000,  0.9091,  1.8182,  2.7273,  3.6364,  4.5455,  5.4545,  6.3636,\n",
      "         7.2727,  8.1818,  9.0909, 10.0000])\n",
      "tensor([1.0000e+00, 8.1113e+00, 6.5793e+01, 5.3367e+02, 4.3288e+03, 3.5112e+04,\n",
      "        2.8480e+05, 2.3101e+06, 1.8738e+07, 1.5199e+08, 1.2328e+09, 1.0000e+10])\n"
     ]
    }
   ],
   "source": [
    "# torch.ARANGE()  Returns type LONG\n",
    "v = torch.arange(0,5)\n",
    "print(v)\n",
    "v = torch.arange(0,5,2) #range(0,5,step=2)\n",
    "print(v)\n",
    "\n",
    "# torch.LINSPACE()   #returns type FLOAT\n",
    "v = torch.linspace(0,10,12) #Split [0,10] in 12 linear steps\n",
    "print(v)\n",
    "v = torch.logspace(0,10,12) #split [0,10] in 12 log steps\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, Slicing, Joining, Mutating\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recombining Data\n",
    "- CONCAT join data on an existing dim\n",
    "- STACK join data on a new dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) torch.Size([9, 3]) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) torch.Size([9, 3]) \n",
      "\n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]]) torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "v = torch.arange(0,9).reshape(3, 3)\n",
    "print(v, '\\n')\n",
    "\n",
    "#CONCATENATE, STACK\n",
    "\"\"\"\n",
    "Both cat and stack require tensors of the same shape.\n",
    "CAT - combines on a given EXISTING dimension\n",
    "STACK - combines tensors on a new dimension\n",
    "\"\"\"\n",
    "#torch.CAT()\n",
    "cat = torch.cat((v,v,v), dim=0) #dim=0 -> columns\n",
    "print(cat, cat.shape,'\\n')\n",
    "\n",
    "cat = torch.cat((v,v,v), dim=0) #dim=1 -> rows\n",
    "print(cat, cat.shape, '\\n')\n",
    "\n",
    "#torch.STACK()\n",
    "stack = torch.stack((v, v),dim=0)\n",
    "print(stack, stack.shape)#stacks array on a new dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [5, 4, 3],\n",
      "        [8, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "#GATHER: Reorganize Data Elements\n",
    "print(v,'\\n')\n",
    "out = torch.gather(v, 1, torch.LongTensor([[0,1,2],[2,1,0],[2,1,2]]))\n",
    "print(out)\n",
    "# torch.gather(input, dim, index, out=None)\n",
    "# out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\n",
    "# out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\n",
    "# out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate a Tensor into multiple.\n",
    "- CHUNK a tensor into N distinct Tensors\n",
    "- SPLIT a tensor every N rows/columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]), tensor([[6, 7, 8]])) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "(tensor([[0, 1],\n",
      "        [3, 4],\n",
      "        [6, 7]]), tensor([[2],\n",
      "        [5],\n",
      "        [8]])) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "#CHUNK A TENSOR, -> Choost the NUMBER OF OUTPUT TENSORS\n",
    "\"\"\"chunk(input, chunks, dim=0)\n",
    "Splits a tensor into a specific number of chunks.\n",
    "Last chunk will be smaller if the tensor size along the given \n",
    "dimension`dim` is not divisible by `chunks`.\"\"\"\n",
    "\n",
    "#Split the tensor into N chunks on dimension 'dim'\n",
    "\n",
    "#Chunk by rows (2D) ~torch.CHUNK()\n",
    "r = torch.chunk(v, 2, dim=0) #2 Chunks, shape (2,3), (1,3)\n",
    "print(r, '\\n')\n",
    "\n",
    "#Recombine\n",
    "print( torch.cat((r[0],r[1]), dim = 0) ,'\\n')\n",
    "\n",
    "#Chunk by columns (2D)\n",
    "r = torch.chunk(v, 2, 1) # 2 tensors, shape (3,2), (3,1)\n",
    "print(r, '\\n')\n",
    "\n",
    "#Recombine\n",
    "print( torch.cat((r[0],r[1]), dim = 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]]) \n",
      "\n",
      "(tensor([[0, 1, 2, 3, 4]]), tensor([[5, 6, 7, 8, 9]]), tensor([[10, 11, 12, 13, 14]]), tensor([[15, 16, 17, 18, 19]]), tensor([[20, 21, 22, 23, 24]])) \n",
      "\n",
      "(tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]]), tensor([[10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19]]), tensor([[20, 21, 22, 23, 24]])) \n",
      "\n",
      "(tensor([[ 0,  1],\n",
      "        [ 5,  6],\n",
      "        [10, 11],\n",
      "        [15, 16],\n",
      "        [20, 21]]), tensor([[ 2,  3],\n",
      "        [ 7,  8],\n",
      "        [12, 13],\n",
      "        [17, 18],\n",
      "        [22, 23]]), tensor([[ 4],\n",
      "        [ 9],\n",
      "        [14],\n",
      "        [19],\n",
      "        [24]]))\n"
     ]
    }
   ],
   "source": [
    "# SPLIT A TENSOR -> choose the SIZE OF OUTPUT TENSORS\n",
    "\"\"\"\n",
    "torch.split(tensor, split_size_or_sections, dim=0)\n",
    "\"\"\"\n",
    "#Split the tensor every N rows/columns on dimension 'dim'\n",
    "v = torch.arange(0,25).view(5,5)\n",
    "print(v,'\\n')\n",
    "\n",
    "\n",
    "#split every 1 rows \n",
    "r = torch.split(v, 1, 0)\n",
    "print(r,'\\n')\n",
    "\n",
    "#Split every 2 rows\n",
    "r = torch.split(v, 2, 0)\n",
    "print(r,'\\n')\n",
    "\n",
    "#Split every 2 columns\n",
    "r = torch.split(v, 2, 1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Select, Mask Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  2],\n",
      "        [ 5,  7],\n",
      "        [10, 12],\n",
      "        [15, 17],\n",
      "        [20, 22]]) \n",
      "\n",
      "tensor([[ 0,  2],\n",
      "        [ 5,  7],\n",
      "        [10, 12],\n",
      "        [15, 17],\n",
      "        [20, 22]]) \n",
      "\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [10, 11, 12, 13, 14]])\n"
     ]
    }
   ],
   "source": [
    "#INDEX SELECT\n",
    "\"\"\"\n",
    "index_select(input, dim, index, out=None) -> Tensor\n",
    "\n",
    "Returns a new tensor which indexes the :attr:`input` tensor \n",
    "along dimension :attr:`dim` using the entries in :attr:`index` \n",
    "which is a `LongTensor`.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#torch.INDEX_SELECT(tensor, dim, index)\n",
    "indx = torch.LongTensor([0,2])\n",
    "r = torch.index_select(v, 1, indx) #Same as v[:,[0,2]] (columns)\n",
    "\n",
    "print(v[:,[0,2]], '\\n')\n",
    "print(r,'\\n')\n",
    "\n",
    "r = torch.index_select(v, 0, indx)\n",
    "print(r) # same as v[[0,2],:]   (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False],\n",
      "        [False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True]]) \n",
      "\n",
      "tensor([ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\n"
     ]
    }
   ],
   "source": [
    "#MASK SELECT\n",
    "\"\"\"\n",
    "masked_select(input, mask, out=None) -> Tensor\n",
    "\n",
    "Returns a new 1-D tensor which indexes the :attr:`input` tensor \n",
    "according to the boolean mask :attr:`mask` which is a `BoolTensor`.\n",
    "\"\"\"\n",
    "\n",
    "mask = v.ge(9) #same as v>=3\n",
    "print(mask, '\\n')\n",
    "r = torch.masked_select(v, mask) # same as v[mask]\n",
    "\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQUEEZE ~ REMOVE UNNECESSARY DIMENSIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.]]]]) torch.Size([2, 1, 1, 2]) \n",
      "\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(2,1,1,2)\n",
    "print(t, t.shape,'\\n')\n",
    "\n",
    "\"\"\"\n",
    "squeeze(input, dim=None, out=None) -> Tensor\n",
    "\n",
    "Returns a tensor with all the dimensions of `input` \n",
    "of size `1` removed.\n",
    "\"\"\"\n",
    "\n",
    "t = torch.squeeze(t)\n",
    "print(t, t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNSQUEEZE ~ X dimension tensor to X+1 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.]) torch.Size([3])\n",
      "tensor([[1., 2., 3.]]) torch.Size([1, 3])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "#ADD EXTRA DIMENSIONS\n",
    "t = torch.Tensor([1,2,3])\n",
    "print(t, t.shape)\n",
    "\n",
    "\"\"\"\n",
    "unsqueeze(input, dim, out=None) -> Tensor\n",
    "\n",
    "Returns a new tensor with a dimension of size one inserted at the\n",
    "specified position.\n",
    "\"\"\"\n",
    "\n",
    "#current dim is (3)\n",
    "#can insert a dimension at 0 -> (1,3)\n",
    "r = torch.unsqueeze(t,0)\n",
    "print(r, r.shape)\n",
    "\n",
    "#or insert dimension at 1 -> (3,1)\n",
    "r = torch.unsqueeze(t,1)\n",
    "print(r, r.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]]) \n",
      "\n",
      "tensor([[ 0,  5, 10, 15, 20],\n",
      "        [ 1,  6, 11, 16, 21],\n",
      "        [ 2,  7, 12, 17, 22],\n",
      "        [ 3,  8, 13, 18, 23],\n",
      "        [ 4,  9, 14, 19, 24]]) \n",
      "\n",
      "tensor([[ 0,  5, 10, 15, 20],\n",
      "        [ 1,  6, 11, 16, 21],\n",
      "        [ 2,  7, 12, 17, 22],\n",
      "        [ 3,  8, 13, 18, 23],\n",
      "        [ 4,  9, 14, 19, 24]])\n"
     ]
    }
   ],
   "source": [
    "print(v,'\\n')\n",
    "\n",
    "\"\"\"\n",
    "transpose(input, dim0, dim1) -> Tensor\n",
    "\n",
    "Returns a tensor that is a transposed version of :attr:`input`.\n",
    "The given dimensions :attr:`dim0` and :attr:`dim1` are swapped.\n",
    "\n",
    "The resulting :attr:`out` tensor shares it's underlying storage with the\n",
    ":attr:`input` tensor, so changing the content of one would change the content\n",
    "of the other.\n",
    "\"\"\"\n",
    "\n",
    "print(torch.transpose(v, 0, 1),'\\n')\n",
    "print(v.T) #SAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNBIND ~ Remove a Tensor Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4366, 0.8218, 0.5861],\n",
      "        [0.9404, 0.6289, 0.4013],\n",
      "        [0.6643, 0.1367, 0.5621]]) torch.Size([3, 3]) \n",
      "\n",
      "(tensor([0.4366, 0.9404, 0.6643]), tensor([0.8218, 0.6289, 0.1367]), tensor([0.5861, 0.4013, 0.5621])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "unbind(input, dim=0) -> seq\n",
    "\n",
    "Removes a tensor dimension.\n",
    "\n",
    "Returns a tuple of all slices along a given dimension, \n",
    "already without it.\n",
    "\"\"\"\n",
    "r = torch.rand(3,3)\n",
    "\n",
    "print(r, r.shape, '\\n')\n",
    "r = torch.unbind(r,1)\n",
    "print(r, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4366, 0.9404, 0.6643],\n",
       "        [0.8218, 0.6289, 0.1367],\n",
       "        [0.5861, 0.4013, 0.5621]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r[0].shape)\n",
    "#UNSQUEEZE (3)->(1,3)\n",
    "r = [torch.unsqueeze(i,0) for i in r]\n",
    "print(r[0].shape)\n",
    "\n",
    "#RECOMBINE ONF NEW DIMENSION\n",
    "torch.cat(r,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4032, 0.6109, 0.4447],\n",
      "        [0.3165, 0.3961, 0.2899],\n",
      "        [0.1884, 0.5292, 0.9387]]) \n",
      "\n",
      "tensor([0.4032, 0.3165, 0.1884, 0.6109, 0.3961, 0.5292, 0.4447, 0.2899, 0.9387])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4032, 0.3165, 0.1884],\n",
       "        [0.6109, 0.3961, 0.5292],\n",
       "        [0.4447, 0.2899, 0.9387]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.rand(3,3)\n",
    "print(r,'\\n')\n",
    "r = torch.unbind(r, 1) #unbind columns\n",
    "\n",
    "print(torch.cat(r)) #stack columns\n",
    "\n",
    "r = [torch.unsqueeze(i, 0) for i in r]\n",
    "torch.cat(r) #same as transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution\n",
    "\n",
    "## Fill a Tensor with randomized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIFORM:  tensor([[0.7576, 0.2793, 0.4031],\n",
      "        [0.7347, 0.0293, 0.7999],\n",
      "        [0.3971, 0.7544, 0.5695]]) \n",
      "\n",
      "UNIFORM (discrete):  tensor([[2., 8., 9.],\n",
      "        [6., 3., 3.],\n",
      "        [0., 2., 1.]]) \n",
      "\n",
      "BERNOULLI:  tensor([[1., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.]]) \n",
      "\n",
      "NORMAL:  tensor([[ 0.0436,  1.3240, -0.1005],\n",
      "        [ 0.6443,  0.5244,  1.0157],\n",
      "        [ 0.2571, -0.9013,  0.8138]]) \n",
      "\n",
      "EXPONENTIAL:  tensor([[0.1522, 0.3676, 0.0485],\n",
      "        [0.0577, 0.1941, 0.8243],\n",
      "        [0.0975, 0.0281, 0.2311]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SET SEED\n",
    "torch.manual_seed(1)\n",
    "\n",
    "#Fill w/ UNIFORM CONTINUOUS random variables (range 0,1)\n",
    "r = torch.Tensor(3,3).uniform_(0, to=1) #torch.rand\n",
    "r = torch.rand(3,3) #SAME\n",
    "print(\"UNIFORM: \",r,'\\n')\n",
    "\n",
    "#Fill w/ UNIFORM DISCRETE rv\n",
    "r= torch.Tensor(3,3).random_(0,10)\n",
    "r = torch.randint(low=0, 10, (3,3)) #SAME\n",
    "print(\"UNIFORM (discrete): \",r,'\\n')\n",
    "\n",
    "## Size: 2x2. BERNOUILLI with probability p stored in elements of r\n",
    "r = torch.Tensor(3,3).bernoulli_(p=0.5)\n",
    "r = torch.rand(3,3)>0.5 #SAME\n",
    "print(\"BERNOULLI: \",r,'\\n')\n",
    "\n",
    "#NORMAL   torch.randn()\n",
    "r = torch.Tensor(3,3).normal_(mean=0, std=1)\n",
    "r = torch.randn(3,3) #SAME\n",
    "print(\"NORMAL: \",r,'\\n')\n",
    "\n",
    "#EXPONENTIAL\n",
    "r = torch.Tensor(3,3).exponential_(lambd=1)\n",
    "print(\"EXPONENTIAL: \",r,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise (Elementwise) Operations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pointwise Ops\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    ".. autofunction:: abs\n",
    ".. autofunction:: acos           - arc cosine\n",
    ".. autofunction:: add\n",
    ".. autofunction:: addcdiv        - element wise: t1 + s * t2/t3\n",
    ".. autofunction:: addcmul        - element wise: t1 + s * t2 * t3\n",
    ".. autofunction:: asin           - arc sin\n",
    ".. autofunction:: atan\n",
    ".. autofunction:: atan2\n",
    ".. autofunction:: ceil           - ceiling\n",
    ".. autofunction:: clamp          - clamp elements into a range\n",
    ".. autofunction:: cos\n",
    ".. autofunction:: cosh\n",
    ".. autofunction:: div            - divide\n",
    ".. autofunction:: erf            - Gaussian error functiom\n",
    ".. autofunction:: erfinv         - Inverse\n",
    ".. autofunction:: exp\n",
    ".. autofunction:: expm1          - exponential of each element minus 1\n",
    ".. autofunction:: floor          \n",
    ".. autofunction:: fmod           - element wise remainder of division\n",
    ".. autofunction:: frac           - fraction part 3.4 -> 0.4\n",
    ".. autofunction:: lerp           - linear interpolation\n",
    ".. autofunction:: log            - natural log\n",
    ".. autofunction:: log1p          - y = log(1 + x)\n",
    ".. autofunction:: mul            - multiple\n",
    ".. autofunction:: neg \n",
    ".. autofunction:: pow\n",
    ".. autofunction:: reciprocal     - 1/x\n",
    ".. autofunction:: remainder      - remainder of division\n",
    ".. autofunction:: round\n",
    ".. autofunction:: rsqrt          - the reciprocal of the square-root \n",
    ".. autofunction:: sigmoid        - sigmode(x)\n",
    ".. autofunction:: sign\n",
    ".. autofunction:: sin\n",
    ".. autofunction:: sinh\n",
    ".. autofunction:: sqrt\n",
    ".. autofunction:: tan\n",
    ".. autofunction:: tanh\n",
    ".. autofunction:: trunc          - truncated integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print(tensor):\n",
    "    print(tensor, tensor.shape,'\\n')\n",
    "\n",
    "r = torch.randn(3,3)\n",
    "_print(r)\n",
    "\n",
    "#ABS VALUES\n",
    "print(\"ABS\")\n",
    "_print(torch.abs(r))\n",
    "\n",
    "#ADD SCALAR\n",
    "print(\"ADD SCALAR\")\n",
    "_print(torch.add(r, 10))\n",
    "\n",
    "#CLAMP TO RANGE [min, max] #will round up\n",
    "print(\"CLAMP [-.5,.5]\")\n",
    "_print(torch.clamp(r,-0.5,0.5))\n",
    "\n",
    "#RECIPROCAL\n",
    "print(\"RECIPROCAL\")\n",
    "_print(torch.reciprocal(r))\n",
    "\n",
    "#EXPONENTIAL\n",
    "print(\"EXPONENTIAL\")\n",
    "_print(torch.exp(r))\n",
    "\n",
    "#NATURAL LOG\n",
    "print(\"LN\")\n",
    "_print(torch.log(r))\n",
    "\n",
    "#Take power of each element in tensor\n",
    "print(\"POWER\")\n",
    "_print(torch.pow(r, 2))\n",
    "\n",
    "#SIGMOID\n",
    "print(\"SIGMOID\")\n",
    "_print(torch.sigmoid(r))\n",
    "\n",
    "#SQRT\n",
    "print(\"SQRT\")\n",
    "_print(torch.sqrt(r))\n",
    "\n",
    "#TRUNCATE TO INTEGER\n",
    "print(\"TRUNC\")\n",
    "_print(torch.trunc(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 1.1250, 2.2500],\n",
      "        [3.3750, 4.5000, 5.6250],\n",
      "        [6.7500, 7.8750, 9.0000]]) \n",
      "\n",
      "SUM tensor([[ 3.3750],\n",
      "        [13.5000],\n",
      "        [23.6250]]) \n",
      "\n",
      "CUMSUM tensor([[ 0.0000,  1.1250,  3.3750],\n",
      "        [ 3.3750,  7.8750, 13.5000],\n",
      "        [ 6.7500, 14.6250, 23.6250]]) \n",
      "\n",
      "PRODUCT tensor([[  0.0000],\n",
      "        [ 85.4297],\n",
      "        [478.4062]]) \n",
      "\n",
      "MEAN tensor([[1.1250],\n",
      "        [4.5000],\n",
      "        [7.8750]]) \n",
      "\n",
      "VARIANCE tensor([[1.2656],\n",
      "        [1.2656],\n",
      "        [1.2656]]) \n",
      "\n",
      "tensor(1.5099) torch.Size([]) \n",
      "\n",
      "tensor(15.3452) torch.Size([]) \n",
      "\n",
      "tensor(15.3452) torch.Size([]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "v = torch.linspace(0,9,9).reshape(3,3)\n",
    "print(v,'\\n')\n",
    "\n",
    "#Sum along dimension\n",
    "print(\"SUM\", torch.sum(v,1,keepdim=True),'\\n') #sum rows\n",
    "\n",
    "#Adds at each element in tensor.\n",
    "print(\"CUMSUM\", torch.cumsum(v, 1),'\\n')\n",
    "\n",
    "#product across dimension\n",
    "print(\"PRODUCT\", torch.prod(v, 1, keepdim=True),'\\n')\n",
    "\n",
    "#mean of rows\n",
    "print(\"MEAN\", torch.mean(v,1,keepdim=True),'\\n')\n",
    "\n",
    "#variance\n",
    "print(\"VARIANCE\", torch.var(v,1,keepdim=True),'\\n')\n",
    "\n",
    "j = torch.rand(3,3)\n",
    "#p-norm calculate the L-p norm of a matrix vectors\n",
    "#p=2 -> y=sqrt(sum(sum(wij^2)))\n",
    "_print(torch.norm(j,p=2)) #L-2 MATRIX NORM\n",
    "\n",
    "\n",
    "#L-2 distance between matrices\n",
    "# ~L2 norm of v-j\n",
    "_print(torch.dist(v,j,p=2))\n",
    "_print(torch.norm(v-j,p=2)) #SAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix - Vector Mutiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplying two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.)\n"
     ]
    }
   ],
   "source": [
    "#Dot product of 2 tensors\n",
    "\"\"\"\n",
    "dot(input, tensor) -> Tensor\n",
    "\n",
    "Computes the dot product (inner product) of two tensors. 1D\n",
    "\"\"\"\n",
    "r = torch.dot(torch.Tensor([4,2]),torch.Tensor([3,1]))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplying a Matrix and a Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matrix - Vector Products\n",
    "mat = torch.arange(8).view(2,4)\n",
    "vec = torch.arange(4)\n",
    "print(mat, mat.shape, '\\n')\n",
    "print(vec, vec.shape,'\\n')\n",
    "\n",
    "r = torch.mv(mat, vec) #similar to dot product\n",
    "print(r,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.arange(8).view(2,4)\n",
    "vec = torch.arange(4)\n",
    "print(mat, mat.shape, '\\n')\n",
    "print(vec, vec.shape,'\\n')\n",
    "\n",
    "r = torch.mvadd(mat, vec) #similar to dot product\n",
    "print(r,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]]) torch.Size([2, 4]) \n",
      "\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]]) torch.Size([4, 1]) \n",
      "\n",
      "tensor([[14],\n",
      "        [38]]) torch.Size([2, 1]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = torch.unsqueeze(vec,1)\n",
    "print(mat, mat.shape, '\\n')\n",
    "print(vec, vec.shape,'\\n')\n",
    "\n",
    "r = torch.mm(mat, vec) #similar to dot product\n",
    "print(r,r.shape,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
